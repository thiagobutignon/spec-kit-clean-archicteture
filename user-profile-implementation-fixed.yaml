# AI-NOTE: This YAML file is the single source of truth for generating domain layers.
# When creating a feature implementation, you MUST adhere to the structure and rules defined here.
version: '3.0.0'
# AI-NOTE: Update these fields to describe the specific feature.
metadata:
  title: 'UserProfile Domain Layer - Clean Architecture'
  description: 'TDD template for user profile feature following the master template rules.'
  source: 'TODO_DOMAIN_TEMPLATE.yaml'
  # AI-NOTE: This should be replaced with the current date, e.g., YYYY-MM-DD.
  lastUpdated: '2025-01-16'

# AI-NOTE: Replace __FEATURE_NAME_KEBAB_CASE__ with the feature name.
structure:
  basePath: 'src/features/user-profile/domain'
  folders:
    - 'errors'      # Feature-specific errors
    - 'use-cases'   # Feature use case interfaces
    - 'test'        # Feature test helpers

# ------------------------------------------------------------------------------
# AI-NOTE: IMMUTABLE SECTIONS AHEAD.
# The sections from here until 'steps' are architectural rules.
# You MUST copy them verbatim into the implementation file without ANY modification.
# ------------------------------------------------------------------------------

layer_rules:
  can_import_from_domain:
    - 'Data Layer - Implements the use case interfaces'
    - 'Presentation Layer - Uses domain types and calls use cases'
    - 'Infrastructure Layer - May use domain types for adapters'
    - 'Main/Factory Layer - Wires everything together, knows all layers'
    - 'Test Files - Can import domain types and interfaces for testing'

  cannot_import_from_domain:
    - 'External Libraries - Should never know about domain'
    - 'Node Modules - Third-party code should not depend on domain'

  domain_cannot_import_from:
    - 'Any other layer - Domain must be completely independent'
    - 'Data Layer - No implementation details'
    - 'Presentation Layer - No UI concerns'
    - 'Infrastructure Layer - No external dependencies'
    - 'Main Layer - No dependency injection logic'
    - 'External Libraries - No third-party dependencies'

# Domain layer rules from templates/DOMAIN_TEMPLATES.md
domain_rules:
  allowed:
    - 'Simple type definitions (Input/Output types)'
    - 'Use case interfaces (contracts only)'
    - 'Domain-specific error classes'
    - 'Test mock functions'

  forbidden:
    - 'Framework dependencies (React, Next.js, Express)'
    - 'External libraries (axios, fetch, database clients)'
    - 'Implementation details of any kind'
    - 'UI components'
    - 'HTTP/Database/File system operations'
    - 'Environment variables'
    - 'Console.log or any I/O operations'
    - 'Value objects'
    - 'Entities'
    - 'Business rules or business logic'
    - 'Validation logic'
    - 'Calculations or computations'
    - 'Any behavior beyond type definitions and interfaces'

# Use case rules from templates/DOMAIN_TEMPLATES.md
use_case_rules:
  should:
    - 'Define only interfaces/contracts, not implementations'
    - 'Have EXACTLY ONE responsibility (one business operation)'
    - 'Do ONE thing and ONE thing only (never multiple operations)'
    - 'Return domain types or primitives'
    - 'Be named with verbs (CreateUser, AuthenticateUser, etc.)'
    - 'Be framework agnostic'

  should_not:
    - 'Contain implementation logic'
    - 'Know about HTTP, databases, or external services'
    - 'Import from data, presentation, or infrastructure layers'
    - 'Have side effects'
    - 'Execute multiple operations (e.g., CreateUserAndSendEmail is wrong)'

# Error rules from templates/DOMAIN_TEMPLATES.md
error_rules:
  should:
    - 'Extend the native Error class'
    - 'Have descriptive names ending with Error'
    - 'Contain meaningful error messages'
    - 'Represent business rule violations'
    - 'Be thrown when domain invariants are violated'

  should_not:
    - 'Contain HTTP status codes'
    - 'Include technical/implementation details'
    - 'Expose sensitive information'
    - 'Import external dependencies'

# Test helper rules from templates/DOMAIN_TEMPLATES.md
test_helper_rules:
  should:
    - 'Create mock/stub implementations of use cases'
    - 'Generate fake test data'
    - 'Be pure functions that return consistent data'
    - 'Help reduce test boilerplate'
    - 'Use ONLY Vitest (Jest is prohibited)'

  should_not:
    - 'Make real API calls or database queries'
    - 'Depend on external services'
    - 'Contain test assertions (those belong in test files)'
    - 'Have side effects or maintain state'
    - 'Use Jest (use Vitest instead)'

# ------------------------------------------------------------------------------
# AI-NOTE: DYNAMIC IMPLEMENTATION SECTION.
# Replicate the generic steps below for each use case, error, and test helper
# required by the feature, replacing the placeholder variables (e.g., __FEATURE_NAME_KEBAB_CASE__).
# ------------------------------------------------------------------------------

steps:
  - id: 'create-feature-branch'
    type: 'branch'
    description: 'Create a new feature branch for User Profile'
    status: 'PENDING'
    rlhf_score: null
    execution_log: ''
    references:
      - type: 'internal_guideline'
        source: 'GIT_WORKFLOW.md'
        description: 'Following git branching best practices for feature development.'
    action:
      branch_name: 'feat/user-profile-domain'
    validation_script: |
      echo "üåø Creating feature branch..."
      # Check if we are on a clean state
      if [ -n "$(git status --porcelain)" ]; then
        echo "‚ö†Ô∏è Warning: You have uncommitted changes. Stashing them..."
        git stash save "Auto-stash before creating feature branch for user-profile"
      fi

      # Get current branch to use as base
      CURRENT_BRANCH=$(git branch --show-current)
      echo "üìç Current branch: $CURRENT_BRANCH"

      # Create and checkout new feature branch
      BRANCH_NAME="feat/user-profile-domain"

      # Check if branch already exists
      if git show-ref --quiet refs/heads/$BRANCH_NAME; then
        echo "‚ö†Ô∏è Branch $BRANCH_NAME already exists. Checking out..."
        git checkout $BRANCH_NAME
      else
        echo "üåø Creating new branch: $BRANCH_NAME"
        git checkout -b $BRANCH_NAME
      fi

      # Verify we're on the correct branch
      CURRENT=$(git branch --show-current)
      if [ "$CURRENT" != "$BRANCH_NAME" ]; then
        echo "‚ùå ERROR: Failed to switch to branch $BRANCH_NAME"
        exit 1
      fi

      echo "‚úÖ Successfully created and switched to branch: $BRANCH_NAME"

  - id: 'create-structure'
    type: 'folder'
    description: 'Create domain folder structure'
    status: 'PENDING' # PENDING | SUCCESS | FAILED | SKIPPED
    rlhf_score: null # -2, -1, 0, 1, 2
    execution_log: ''
    # AI-NOTE: 'references' for this step can be left empty or link to architectural decision records.
    references:
      - type: 'internal_guideline'
        source: 'ARCHITECTURE.md'
        description: 'Following the standard feature-based domain structure.'
    action:
      create_folders:
        basePath: 'src/features/user-profile/domain'
        folders:
          - 'errors'
          - 'use-cases'
          - 'test'
    validation_script: |
      echo "‚úÖ Verifying folder structure..."
      # Adiciona uma verifica√ß√£o expl√≠cita para falhar se as pastas n√£o existirem
      if [ ! -d "src/features/user-profile/domain/errors" ] || \
         [ ! -d "src/features/user-profile/domain/use-cases" ] || \
         [ ! -d "src/features/user-profile/domain/test" ]; then
        echo "‚ùå ERROR: One or more domain folders were not created."
        exit 1
      fi
      echo "‚úÖ Folders exist."

      echo "üì¶ Staging changes..."
      git add .

      echo "üíæ Creating commit..."
      git commit -m "feat(user-profile): create domain folder structure"
      if [ $? -ne 0 ]; then
        echo "‚ùå COMMIT FAILED - Checking git status..."
        git status
        echo "üìã Review the status above and fix any issues"
        exit 1
      fi
      echo "‚úÖ Successfully committed"

  # Step 2: Create first use case
  - id: 'create-use-case-get-user-profile'
    type: 'create_file'
    description: 'Create GetUserProfile use case interface'
    status: 'PENDING' # PENDING | SUCCESS | FAILED | SKIPPED
    rlhf_score: null # -2, -1, 0, 1, 2
    execution_log: ''
    # AI-NOTE: For each step, you MUST populate this 'references' section.
    # Use 'context7' for external design patterns and 'serena' for internal codebase analysis.
    references:
      - type: 'external_pattern' # 'external_pattern' or 'internal_code_analysis'
        source: 'context7'
        query: 'awesome system design user profile retrieval'
        url: 'https://github.com/donnemartin/system-design-primer'
        description: 'This use case follows the Command pattern for handling actions.'
      - type: 'internal_code_analysis'
        source: 'serena'
        tool: 'find_symbol'
        query: '*UseCase'
        description: 'The structure is consistent with existing use cases like `OtherUseCase` found in the project.'
    path: 'src/features/user-profile/domain/use-cases/get-user-profile.ts'
    template: |
      /**
       * Input parameters for GetUserProfileUseCase
       */
      export type GetUserProfileInput = {
        userId: string
      }

      /**
       * Output type for GetUserProfileUseCase
       */
      export type GetUserProfileOutput = {
        id: string
        email: string
        firstName: string
        lastName: string
      }

      /**
       * GetUserProfileUseCase interface
       * @description Retrieves a user's profile information
       */
      export interface GetUserProfileUseCase {
        /**
         * Execute the get user profile operation
         * @param input - The input parameters
         * @returns Promise with the operation output
         */
        execute: (input: GetUserProfileInput) => Promise<GetUserProfileOutput>
      }
    validation_script: |
      # AI-NOTE: This script is immutable. Only the commit message placeholder is replaced.
      echo "üîç Running lint check..."
      yarn lint
      if [ $? -ne 0 ]; then
        echo "‚ùå LINT FAILED - Attempting auto-fix..."
        yarn lint --fix
        if [ $? -ne 0 ]; then
          echo "‚ùå AUTO-FIX FAILED - Manual intervention required"
          echo "üìã Run 'yarn lint' to see remaining errors"
          exit 1
        fi
        echo "‚úÖ Lint errors auto-fixed, validating again..."
        yarn lint
        if [ $? -ne 0 ]; then
          echo "‚ùå LINT STILL FAILING - Manual fixes needed"
          exit 1
        fi
      fi
      echo "‚úÖ Lint passed"

      echo "üß™ Running tests with coverage..."
      yarn test --coverage
      if [ $? -ne 0 ]; then
        echo "‚ùå TESTS FAILED - Running specific test to identify issue..."
        yarn test --run --reporter=verbose
        echo "‚ùå Tests must be fixed manually"
        echo "üìã Check the test output above for details"
        exit 1
      fi
      echo "‚úÖ Tests passed"

      echo "üì¶ Staging changes..."
      git add .

      echo "üíæ Creating commit..."
      git commit -m "feat(user-profile): add get-user-profile use case"
      if [ $? -ne 0 ]; then
        echo "‚ùå COMMIT FAILED - Checking git status..."
        git status
        echo "üìã Review the status above and fix any issues"
        exit 1
      fi
      echo "‚úÖ Successfully committed"

  # Step 3: Create error class
  - id: 'create-error-user-not-found'
    type: 'create_file'
    description: 'Create user-not-found domain error'
    status: 'PENDING' # PENDING | SUCCESS | FAILED | SKIPPED
    rlhf_score: null # -2, -1, 0, 1, 2
    execution_log: ''
    # AI-NOTE: For each step, you MUST populate this 'references' section.
    # Use 'context7' for external design patterns and 'serena' for internal codebase analysis.
    references:
      - type: 'external_pattern' # 'external_pattern' or 'internal_code_analysis'
        source: 'context7'
        query: 'awesome system design error handling'
        url: 'https://github.com/goldbergyoni/nodebestpractices'
        description: 'This error follows best practices for domain error handling.'
      - type: 'internal_code_analysis'
        source: 'serena'
        tool: 'find_symbol'
        query: '*Error'
        description: 'The structure is consistent with existing error classes found in the project.'
    path: 'src/features/user-profile/domain/errors/user-not-found.ts'
    template: |
      /**
       * Error thrown when the requested user does not exist
       * @extends Error
       */
      export class UserNotFoundError extends Error {
        constructor() {
          super('User with the given ID was not found')
          this.name = 'UserNotFoundError'
        }
      }
    validation_script: |
      echo "üîç Running lint check..."
      yarn lint
      if [ $? -ne 0 ]; then
        echo "‚ùå LINT FAILED - Attempting auto-fix..."
        yarn lint --fix
        if [ $? -ne 0 ]; then
          echo "‚ùå AUTO-FIX FAILED - Manual intervention required"
          echo "üìã Run 'yarn lint' to see remaining errors"
          exit 1
        fi
        echo "‚úÖ Lint errors auto-fixed, validating again..."
        yarn lint
        if [ $? -ne 0 ]; then
          echo "‚ùå LINT STILL FAILING - Manual fixes needed"
          exit 1
        fi
      fi
      echo "‚úÖ Lint passed"

      echo "üß™ Running tests with coverage..."
      yarn test --coverage
      if [ $? -ne 0 ]; then
        echo "‚ùå TESTS FAILED - Running specific test to identify issue..."
        yarn test --run --reporter=verbose
        echo "‚ùå Tests must be fixed manually"
        echo "üìã Check the test output above for details"
        exit 1
      fi
      echo "‚úÖ Tests passed"

      echo "üì¶ Staging changes..."
      git add .

      echo "üíæ Creating commit..."
      git commit -m "feat(user-profile): add user-not-found domain error"
      if [ $? -ne 0 ]; then
        echo "‚ùå COMMIT FAILED - Checking git status..."
        git status
        echo "üìã Review the status above and fix any issues"
        exit 1
      fi
      echo "‚úÖ Successfully committed"

  # Step 4: Create test helper
  - id: 'create-test-helper-get-user-profile'
    type: 'create_file'
    description: 'Create mock for GetUserProfile use case'
    status: 'PENDING' # PENDING | SUCCESS | FAILED | SKIPPED
    rlhf_score: null # -2, -1, 0, 1, 2
    execution_log: ''
    # AI-NOTE: For each step, you MUST populate this 'references' section.
    # Use 'context7' for external design patterns and 'serena' for internal codebase analysis.
    references:
      - type: 'external_pattern' # 'external_pattern' or 'internal_code_analysis'
        source: 'context7'
        query: 'vitest testing best practices'
        url: 'https://vitest.dev/guide/mocking'
        description: 'Following Vitest best practices for creating test mocks.'
      - type: 'internal_code_analysis'
        source: 'serena'
        tool: 'find_symbol'
        query: 'mock*UseCase'
        description: 'The structure is consistent with existing test helpers found in the project.'
    path: 'src/features/user-profile/domain/test/mock-get-user-profile-use-case.ts'
    template: |
      import { vi } from 'vitest'
      import type { GetUserProfileUseCase, GetUserProfileInput, GetUserProfileOutput } from '../use-cases/get-user-profile'

      /**
       * Creates a mock instance of GetUserProfileInput
       * @returns Mock input for testing
       */
      export const mockGetUserProfileInput = (): GetUserProfileInput => ({
        userId: 'user-123'
      })

      /**
       * Creates a mock instance of GetUserProfileOutput
       * @returns Mock output for testing
       */
      export const mockGetUserProfileOutput = (): GetUserProfileOutput => ({
        id: 'user-123',
        email: 'test@example.com',
        firstName: 'John',
        lastName: 'Doe'
      })

      /**
       * Creates a mock instance of GetUserProfileUseCase
       * @returns Mocked use case with vitest functions
       */
      export const mockGetUserProfileUseCase = (): GetUserProfileUseCase => ({
        execute: vi.fn()
      })
    validation_script: |
      echo "üîç Running lint check..."
      yarn lint
      if [ $? -ne 0 ]; then
        echo "‚ùå LINT FAILED - Attempting auto-fix..."
        yarn lint --fix
        if [ $? -ne 0 ]; then
          echo "‚ùå AUTO-FIX FAILED - Manual intervention required"
          echo "üìã Run 'yarn lint' to see remaining errors"
          exit 1
        fi
        echo "‚úÖ Lint errors auto-fixed, validating again..."
        yarn lint
        if [ $? -ne 0 ]; then
          echo "‚ùå LINT STILL FAILING - Manual fixes needed"
          exit 1
        fi
      fi
      echo "‚úÖ Lint passed"

      echo "üß™ Running tests with coverage..."
      yarn test --coverage
      if [ $? -ne 0 ]; then
        echo "‚ùå TESTS FAILED - Running specific test to identify issue..."
        yarn test --run --reporter=verbose
        echo "‚ùå Tests must be fixed manually"
        echo "üìã Check the test output above for details"
        exit 1
      fi
      echo "‚úÖ Tests passed"

      echo "üì¶ Staging changes..."
      git add .

      echo "üíæ Creating commit..."
      git commit -m "test(user-profile): add get-user-profile use case test helpers"
      if [ $? -ne 0 ]; then
        echo "‚ùå COMMIT FAILED - Checking git status..."
        git status
        echo "üìã Review the status above and fix any issues"
        exit 1
      fi
      echo "‚úÖ Successfully committed"

  # Final Step: Create Pull Request to staging
  - id: 'create-pull-request'
    type: 'pull_request'
    description: 'Create pull request for User Profile domain to staging'
    status: 'PENDING'
    rlhf_score: null
    execution_log: ''
    references:
      - type: 'internal_guideline'
        source: 'GIT_WORKFLOW.md'
        description: 'Following PR process for feature integration to staging.'
    action:
      target_branch: 'staging'
      source_branch: 'feat/user-profile-domain'
      title: 'feat(user-profile): implement domain layer'
    validation_script: |
      echo "üöÄ Preparing to create pull request..."

      # Push the current branch to remote
      echo "üì§ Pushing branch to remote..."
      git push --set-upstream origin feat/user-profile-domain
      if [ $? -ne 0 ]; then
        echo "‚ùå ERROR: Failed to push branch to remote"
        exit 1
      fi

      # Check if gh CLI is available
      if ! command -v gh &> /dev/null; then
        echo "‚ö†Ô∏è GitHub CLI (gh) is not installed."
        echo "üìã Please create PR manually at:"
        echo "   https://github.com/$(git remote get-url origin | sed 's/.*github.com[:/]\(.*\)\.git/\1/')/pull/new/feat/user-profile-domain"
        exit 0
      fi

      # Create the pull request
      echo "üîÑ Creating pull request to staging..."
      PR_BODY="## Summary

      Implementation of domain layer for User Profile feature.

      ### Changes included:
      - Use case interfaces (GetUserProfile)
      - Domain errors (UserNotFound)
      - Test helpers and mocks

      ### Domain Layer Compliance:
      - ‚úÖ No external dependencies
      - ‚úÖ Only interfaces and types
      - ‚úÖ Follows Clean Architecture principles
      - ‚úÖ All tests passing
      - ‚úÖ Lint checks passed

      ### Generated by:
      - Template: DOMAIN_TEMPLATE.yaml
      - Date: $(date +%Y-%m-%d)

      ---
      ü§ñ Generated with spec-kit-clean-architecture"

      gh pr create \
        --base staging \
        --head feat/user-profile-domain \
        --title "feat(user-profile): implement domain layer" \
        --body "$PR_BODY" \
        --assignee @me

      if [ $? -eq 0 ]; then
        echo "‚úÖ Pull request created successfully!"

        # Show PR URL
        PR_URL=$(gh pr view --json url -q .url)
        echo "üìé Pull Request URL: $PR_URL"

        # Optionally open in browser
        echo "üåê Opening PR in browser..."
        gh pr view --web
      else
        echo "‚ö†Ô∏è Could not create PR automatically. Please create manually:"
        echo "   gh pr create --base staging --head feat/user-profile-domain"
      fi

# ------------------------------------------------------------------------------
# AI-NOTE: IMMUTABLE DOCUMENTATION SECTIONS AHEAD.
# Copy these sections verbatim. The [placeholders] inside the commands
# are for HUMAN examples and MUST NOT be replaced by the AI.
# ------------------------------------------------------------------------------

troubleshooting:
  lint_fails:
    - 'DO NOT commit - Fix all lint errors first'
    - 'Check for unused imports'
    - 'Verify proper TypeScript types'
    - 'Ensure no console.log statements'
    - 'Run yarn lint --fix to auto-fix when possible'

  tests_fail:
    - 'DO NOT commit - All tests must pass'
    - 'Check if mocks match the actual interfaces'
    - 'Verify Input/Output types are correct'
    - 'Ensure test coverage meets requirements'
    - 'Run specific test: yarn test [test-file-path]'

  typescript_fails:
    - 'Check all type definitions match'
    - 'Ensure no missing imports'
    - 'Verify interface implementations are complete'
    - 'Run yarn tsc --noEmit to check types'

# Refactoring checklist from templates/DOMAIN_TEMPLATES.md
refactoring:
  before_refactoring: |
    # Check current status and differences
    echo "üìä Checking current changes..."
    git status
    git diff

    # Ensure clean working directory
    echo "‚úÖ Saving current work..."
    git stash save "WIP: before refactoring"

    # Create refactoring branch
    echo "üåø Creating refactor branch..."
    git checkout -b refactor/[feature-name]

    # Run tests to ensure starting point is stable
    echo "üß™ Validating current state..."
    yarn test --run
    if [ $? -ne 0 ]; then
      echo "‚ùå Tests failing before refactor - fix first!"
      exit 1
    fi
    echo "‚úÖ Ready to refactor"

  during_refactoring: |
    # After each change, check what was modified
    echo "üîç Reviewing changes..."
    git diff --stat
    git diff

    # Validate the change
    yarn lint && yarn test --run

    # Commit atomically
    git add -p  # Interactive staging to commit only related changes
    git commit -m "refactor([feature-name]): [specific change description]"

    # Show what was changed in the last commit
    git show --stat

  common_scenarios:
    - name: 'Splitting a use case'
      wrong_example: |
        interface CreateUserAndSendEmailUseCase {
          execute: (input: CreateUserAndSendEmailInput) => Promise<CreateUserAndSendEmailOutput>
        }
      correct_example: |
        interface CreateUserUseCase {
          execute: (input: CreateUserInput) => Promise<CreateUserOutput>
        }
        interface SendWelcomeEmailUseCase {
          execute: (input: SendWelcomeEmailInput) => Promise<SendWelcomeEmailOutput>
        }
      script: |
        # Split the combined use case into separate files
        # Update all imports and references
        # Run tests after each change

    - name: 'Renaming for clarity'
      script: |
        # 1. See all occurrences before changing
        echo "üîç Finding all occurrences of [OldName]..."
        grep -r "[OldName]" src/features/[feature-name]/

        # 2. Perform the rename
        echo "‚úèÔ∏è Renaming [OldName] to [NewName]..."
        # Update files...

        # 3. Review the changes
        echo "üìä Reviewing rename changes..."
        git diff --word-diff

        # 4. Validate nothing broke
        yarn lint && yarn test --run

        # 5. Check if rename is complete
        echo "üîç Ensuring no [OldName] remains..."
        grep -r "[OldName]" src/features/[feature-name]/
        if [ $? -eq 0 ]; then
          echo "‚ö†Ô∏è Warning: [OldName] still found in some files"
        fi

        # 6. Commit the rename
        git add .
        git commit -m "refactor([feature-name]): rename [OldName] to [NewName] for clarity"

        # 7. Show the final diff
        git show --stat

# Recovery steps from templates/DOMAIN_TEMPLATES.md
recovery:
  accidental_commit: |
    # Revert the last commit but keep changes
    git reset --soft HEAD~1

    # Fix the issues
    # ... make corrections ...

    # Re-run validation
    yarn lint
    yarn test --coverage

    # Commit again with fixed code
    git add .
    git commit -m "[original message] - fixed"

  domain_polluted: |
    # 1. Identify violations in domain
    echo "üîç Checking for domain violations..."
    git diff src/features/[feature-name]/domain/

    # Check for forbidden patterns
    echo "‚ö†Ô∏è Checking for business logic..."
    grep -r "class.*{.*calculate\|validate\|process" src/features/[feature-name]/domain/

    echo "‚ö†Ô∏è Checking for external dependencies..."
    grep -r "import.*axios\|fetch\|http" src/features/[feature-name]/domain/

    echo "‚ö†Ô∏è Checking for console logs..."
    grep -r "console\." src/features/[feature-name]/domain/

    # 2. Show what needs to be moved
    git diff src/features/[feature-name]/domain/ --name-only

    # 3. After moving code to proper layers
    echo "‚úÖ Validating domain is clean..."
    yarn lint
    yarn test --run

    # 4. Commit the cleanup
    git add .
    git diff --staged --stat
    git commit -m "refactor([feature-name]): remove business logic from domain layer"

# AI Guidelines from templates/DOMAIN_TEMPLATES.md
ai_guidelines:
  - 'Always validate before committing: Run lint first, Run tests second, Only commit if both pass'
  - 'If generation fails: Identify the specific error, Fix only that error, Re-run validation, Do NOT proceed until fixed'
  - 'Follow the principle: One use case = One file = One responsibility'
  - 'If tempted to add "And" in a use case name, split it'
  - 'When in doubt: Choose simplicity over complexity, Split rather than combine, Ask for clarification rather than assume'
  - 'MUST generate different case styles from the input names (e.g., "Add Item To Cart" becomes: PascalCase=AddItemToCart, kebab-case=add-item-to-cart, lower case=add item to cart).'
  - 'MUST replace ALL placeholder variables (like __FEATURE_NAME_KEBAB_CASE__) with actual values'
  - 'MUST NOT leave any placeholder variables in the final implementation'
  - 'MUST NOT replace any [placeholders] found inside documentation sections like refactoring or recovery' # Adicionar esta regra para clareza extra
  - 'MUST use vitest, NOT jest'
  - 'MUST follow all domain rules - no business logic, no external dependencies'

# ------------------------------------------------------------------------------
# AI-NOTE: TASK EVALUATION SECTION.
# After the entire execution is complete, this section will be populated by a
# human reviewer or an evaluation script.
# ------------------------------------------------------------------------------

evaluation:
  # AI-NOTE: This final_status will be 'SUCCESS' if all steps passed, or 'FAILED' if any step failed.
  final_status: 'PENDING' # PENDING | SUCCESS | FAILED
  # AI-NOTE: The final_rlhf_score is an overall score for the entire task, assigned by a human reviewer.
  final_rlhf_score: null # -2, -1, 0, 1, 2
  # AI-NOTE: The reviewer will add a summary of what went well and what could be improved.
  # This text is the primary source for future learning and template improvements.
  reviewer_summary: |
    - What went well:
      - ...
    - Areas for improvement:
      - ...
  # AI-NOTE: This section lists actionable suggestions for improving the master templates or prompts.
  # This is the key to the continuous learning loop.
  template_improvement_suggestions:
    - target_template: 'domain.template.yaml'
      target_step_id: 'create-use-case-get-user-profile'
      suggestion: 'The generated mock data was too simplistic. The template should be updated to include more realistic data generation.'
      priority: 'medium'