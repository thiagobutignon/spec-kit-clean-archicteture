# ============= BEGIN DATA STEPS BACKEND SECTION =============

  # ------------------------------------------------------------------------------
  # AI-NOTE: DATA LAYER IMPLEMENTATION STEPS FOR BACKEND WITH TDD
  # Following Test-Driven Development (TDD): RED ‚Üí GREEN ‚Üí REFACTOR
  # Tests are created FIRST (RED), then implementation (GREEN)
  # ------------------------------------------------------------------------------

  # ------------------------------------------------------------------------------
  # DATA LAYER STEPS SECTION
  # Steps for implementing data layer following TDD methodology
  # Each use case implementation starts with failing tests
  # ------------------------------------------------------------------------------

  data_steps:
    # === STEP 1: CREATE FEATURE BRANCH ===
    - id: 'create-feature-branch-data-__USE_CASE_NAME_KEBAB_CASE__'
      type: 'validation'
      description: 'Create and checkout feature branch for __USE_CASE_NAME_PASCAL_CASE__ data implementation'
      status: 'PENDING'
      rlhf_score: null
      execution_log: ''
      references:
        - type: 'internal_guideline'
          source: 'GIT_WORKFLOW.md'
          description: 'Git branching strategy and naming conventions for data layer'
      run_scripts:
        description: 'Create feature branch with proper naming convention for data layer'
        scripts:
          - name: 'Create data feature branch'
            command: |
              # Stash any uncommitted changes
              git stash save "WIP: Before creating __USE_CASE_NAME_KEBAB_CASE__-data branch"

              # Ensure we're on the main branch and up to date
              git checkout main || git checkout master
              git pull origin main || git pull origin master

              # Create and checkout new feature branch
              BRANCH_NAME="feat/__USE_CASE_NAME_KEBAB_CASE__-data-layer"
              git checkout -b "$BRANCH_NAME" || {
                echo "‚ùå Failed to create branch: $BRANCH_NAME"
                exit 1
              }

              echo "‚úÖ Created and checked out branch: $BRANCH_NAME"
            workingDirectory: '__PROJECT_NAME__'

    # === STEP 2: CREATE DATA STRUCTURE ===
    - id: 'create-data-structure-__USE_CASE_NAME_KEBAB_CASE__'
      type: 'folder'
      description: 'Create data layer folder structure for __USE_CASE_NAME_PASCAL_CASE__ use case'
      status: 'PENDING' # PENDING | SUCCESS | FAILED | SKIPPED
      rlhf_score: null # -2, -1, 0, 1, 2
      execution_log: ''
      references:
        - type: 'internal_guideline'
          source: 'BACKEND_ARCHITECTURE.md'
          description: 'Following Clean Architecture data layer structure for backend.'
        - type: 'external_pattern'
          source: 'context7'
          query: 'clean architecture data layer TDD backend node.js'
          url: 'https://github.com/...'
          description: 'Data layer patterns with TDD for backend development.'
      action:
        create_folders:
          basePath: '__PROJECT_NAME__/src/features/__FEATURE_NAME_KEBAB_CASE__/__USE_CASE_NAME_KEBAB_CASE__/data'
          folders:
            - 'usecases'      # Use case implementations for this specific use case
            - 'protocols'     # Protocols/contracts for dependencies (if needed)
      validation_script: |
        # AI-NOTE: Replace placeholders but keep shell variables intact
        BASE_PATH="__PROJECT_NAME__/src/features/__FEATURE_NAME_KEBAB_CASE__/__USE_CASE_NAME_KEBAB_CASE__/data"
        FOLDERS="$BASE_PATH/usecases"
        echo "‚úÖ Verifying data folder structure..."
        for folder in $FOLDERS; do
          if [ ! -d "$folder" ]; then
            echo "‚ùå ERROR: Folder $folder was not created."
            exit 1
          fi
        done
        echo "‚úÖ All data folders exist for __USE_CASE_NAME_PASCAL_CASE__ use case."

    # === STEP 3: CREATE TEST FIRST (TDD RED PHASE) ===
    - id: 'create-data-test-red-__USE_CASE_NAME_KEBAB_CASE__'
      type: 'create_file'
      description: 'Create failing test for __USE_CASE_NAME_PASCAL_CASE__ data implementation (TDD RED)'
      status: 'PENDING'
      rlhf_score: null
      execution_log: ''
      references:
        - type: 'external_pattern'
          source: 'context7'
          query: 'TDD test first red phase jest typescript'
          url: 'https://github.com/...'
          description: 'TDD Red phase - writing failing tests first.'
        - type: 'internal_guideline'
          source: 'TESTING_GUIDE.md'
          description: 'Following TDD methodology - test first approach.'
      path: '__PROJECT_NAME__/src/features/__FEATURE_NAME_KEBAB_CASE__/__USE_CASE_NAME_KEBAB_CASE__/data/usecases/db-__USE_CASE_NAME_KEBAB_CASE__.spec.ts'
      template: |
        import { Db__USE_CASE_NAME_PASCAL_CASE__ } from './db-__USE_CASE_NAME_KEBAB_CASE__'
        import {
          __USE_CASE_NAME_PASCAL_CASE__,
          __USE_CASE_NAME_PASCAL_CASE__Input,
          __USE_CASE_NAME_PASCAL_CASE__Output
        } from '../../domain/usecases/__USE_CASE_NAME_KEBAB_CASE__'
        // AI-NOTE: Import domain errors if they exist
        // import { __USE_CASE_NAME_PASCAL_CASE__Error } from '../../domain/errors/__USE_CASE_NAME_KEBAB_CASE__-error'

        /**
         * Test suite for Db__USE_CASE_NAME_PASCAL_CASE__ implementation
         * Following TDD - Test First Approach (RED Phase)
         * @layer Data Layer Tests
         * @pattern TDD - Red-Green-Refactor
         */
        describe('Db__USE_CASE_NAME_PASCAL_CASE__', () => {
          // AI-NOTE: Mock repository if needed
          const make__FEATURE_NAME_PASCAL_CASE__RepositoryStub = () => {
            class __FEATURE_NAME_PASCAL_CASE__RepositoryStub {
              async __REPOSITORY_METHOD_NAME__(data: any): Promise<any> {
                return {
                  id: 'any_id',
                  ...data,
                  createdAt: new Date('2024-01-01'),
                  updatedAt: new Date('2024-01-01')
                }
              }
            }
            return new __FEATURE_NAME_PASCAL_CASE__RepositoryStub()
          }

          const makeSut = () => {
            const __FEATURE_NAME_CAMEL_CASE__RepositoryStub = make__FEATURE_NAME_PASCAL_CASE__RepositoryStub()
            const sut = new Db__USE_CASE_NAME_PASCAL_CASE__(__FEATURE_NAME_CAMEL_CASE__RepositoryStub)
            return {
              sut,
              __FEATURE_NAME_CAMEL_CASE__RepositoryStub
            }
          }

          const makeFakeInput = (): __USE_CASE_NAME_PASCAL_CASE__Input => ({
            __INPUT_FIELD_1__: 'any_value_1',
            __INPUT_FIELD_2__: 'any_value_2',
            __INPUT_FIELD_3__: 'any_value_3'
          })

          describe('execute', () => {
            test('Should call repository with correct values', async () => {
              // This test will FAIL initially (RED phase)
              const { sut, __FEATURE_NAME_CAMEL_CASE__RepositoryStub } = makeSut()
              const spy = jest.spyOn(__FEATURE_NAME_CAMEL_CASE__RepositoryStub, '__REPOSITORY_METHOD_NAME__')
              const input = makeFakeInput()

              await sut.execute(input)

              expect(spy).toHaveBeenCalledWith({
                __INPUT_FIELD_1__: 'any_value_1',
                __INPUT_FIELD_2__: 'any_value_2',
                __INPUT_FIELD_3__: 'any_value_3'
              })
            })

            test('Should return correct output on success', async () => {
              // This test will FAIL initially (RED phase)
              const { sut } = makeSut()
              const input = makeFakeInput()

              const output = await sut.execute(input)

              expect(output).toEqual({
                __OUTPUT_FIELD_1__: expect.any(String),
                __OUTPUT_FIELD_2__: expect.any(String),
                __OUTPUT_FIELD_3__: expect.any(String),
                __TIMESTAMP_FIELD__: expect.any(Date)
              })
            })

            test('Should throw if repository throws', async () => {
              // This test will FAIL initially (RED phase)
              const { sut, __FEATURE_NAME_CAMEL_CASE__RepositoryStub } = makeSut()
              jest.spyOn(__FEATURE_NAME_CAMEL_CASE__RepositoryStub, '__REPOSITORY_METHOD_NAME__')
                .mockRejectedValueOnce(new Error('Repository error'))
              const input = makeFakeInput()

              const promise = sut.execute(input)

              await expect(promise).rejects.toThrow('Repository error')
            })

            test('Should handle business rules correctly', async () => {
              // AI-NOTE: Add specific business rule tests based on use case
              // This test will FAIL initially (RED phase)
              const { sut } = makeSut()
              const input = makeFakeInput()

              const output = await sut.execute(input)

              // Business rule validations
              expect(output.__OUTPUT_FIELD_1__).toBeTruthy()
              expect(output.__TIMESTAMP_FIELD__.getTime()).toBeGreaterThan(0)
            })
          })
        })
      validation_script: |
        echo "üî¥ Running TDD RED phase - tests should FAIL..."
        npm run test -- src/features/__FEATURE_NAME_KEBAB_CASE__/__USE_CASE_NAME_KEBAB_CASE__/data/usecases/db-__USE_CASE_NAME_KEBAB_CASE__.spec.ts --no-coverage

        # AI-NOTE: We expect tests to fail at this point (RED phase)
        if [ $? -eq 0 ]; then
          echo "‚ö†Ô∏è  WARNING: Tests passed but they should fail in RED phase"
          echo "   Please verify test implementation"
        else
          echo "‚úÖ RED phase complete - tests are failing as expected"
          echo "   Ready to implement the data layer (GREEN phase)"
        fi

        git add .
        git commit -m "test(data): add failing tests for __USE_CASE_NAME_KEBAB_CASE__ (TDD RED phase)"

    # === STEP 4: CREATE REPOSITORY PROTOCOL (IF NEEDED) ===
    - id: 'create-repository-protocol-__USE_CASE_NAME_KEBAB_CASE__'
      type: 'conditional_file'
      description: 'Create repository protocol if data layer needs database access'
      condition: 'check_if_repository_needed'
      status: 'PENDING'
      rlhf_score: null
      execution_log: ''
      references:
        - type: 'internal_guideline'
          source: 'BACKEND_ARCHITECTURE.md'
          description: 'Repository pattern for data layer abstraction.'
      path: '__PROJECT_NAME__/src/features/__FEATURE_NAME_KEBAB_CASE__/__USE_CASE_NAME_KEBAB_CASE__/data/protocols/__REPOSITORY_PROTOCOL_NAME__.ts'
      template: |
        /**
         * Protocol for __FEATURE_NAME_PASCAL_CASE__ repository
         * Defines the contract for database operations
         * @layer Data Layer Protocol
         * @pattern Repository Pattern
         */
        export interface __REPOSITORY_PROTOCOL_NAME__ {
          /**
           * __REPOSITORY_METHOD_DESCRIPTION__
           * @param data - Data to be processed
           * @returns Promise with the result
           */
          __REPOSITORY_METHOD_NAME__: (data: __REPOSITORY_INPUT_TYPE__) => Promise<__REPOSITORY_OUTPUT_TYPE__>
        }

        /**
         * Input type for repository operation
         */
        export type __REPOSITORY_INPUT_TYPE__ = {
          __INPUT_FIELD_1__: string
          __INPUT_FIELD_2__: string
          __INPUT_FIELD_3__: string
        }

        /**
         * Output type for repository operation
         */
        export type __REPOSITORY_OUTPUT_TYPE__ = {
          id: string
          __OUTPUT_FIELD_1__: string
          __OUTPUT_FIELD_2__: string
          __OUTPUT_FIELD_3__: string
          createdAt: Date
          updatedAt: Date
        }

    # === STEP 5: CREATE DATA IMPLEMENTATION (TDD GREEN PHASE) ===
    - id: 'create-data-implementation-green-__USE_CASE_NAME_KEBAB_CASE__'
      type: 'create_file'
      description: 'Create __USE_CASE_NAME_PASCAL_CASE__ data implementation to make tests pass (TDD GREEN)'
      status: 'PENDING'
      rlhf_score: null
      execution_log: ''
      references:
        - type: 'external_pattern'
          source: 'context7'
          query: 'clean architecture data layer implementation dependency injection'
          url: 'https://github.com/...'
          description: 'Data layer implementation with dependency injection.'
        - type: 'internal_guideline'
          source: 'TESTING_GUIDE.md'
          description: 'TDD Green phase - making tests pass.'
      path: '__PROJECT_NAME__/src/features/__FEATURE_NAME_KEBAB_CASE__/__USE_CASE_NAME_KEBAB_CASE__/data/usecases/db-__USE_CASE_NAME_KEBAB_CASE__.ts'
      template: |
        import {
          __USE_CASE_NAME_PASCAL_CASE__,
          __USE_CASE_NAME_PASCAL_CASE__Input,
          __USE_CASE_NAME_PASCAL_CASE__Output
        } from '../../domain/usecases/__USE_CASE_NAME_KEBAB_CASE__'
        // AI-NOTE: Import repository protocol if it exists
        import type { __REPOSITORY_PROTOCOL_NAME__ } from '../protocols/__REPOSITORY_PROTOCOL_NAME__'

        /**
         * Data implementation of __USE_CASE_NAME_PASCAL_CASE__ use case
         * Implements domain interface with dependency injection
         * @layer Data Layer
         * @pattern Dependency Injection, Repository Pattern
         * @implements __USE_CASE_NAME_PASCAL_CASE__
         */
        export class Db__USE_CASE_NAME_PASCAL_CASE__ implements __USE_CASE_NAME_PASCAL_CASE__ {
          /**
           * Constructor with dependency injection
           * @param __FEATURE_NAME_CAMEL_CASE__Repository - Repository for database operations
           */
          constructor(
            private readonly __FEATURE_NAME_CAMEL_CASE__Repository: __REPOSITORY_PROTOCOL_NAME__
          ) {}

          /**
           * Validate input data before processing
           * @param input - Input to validate
           * @throws Error if input is invalid
           * @private
           */
          private validateInput(input: __USE_CASE_NAME_PASCAL_CASE__Input): void {
            if (!input.__INPUT_FIELD_1__) {
              throw new Error('Missing required field: __INPUT_FIELD_1__')
            }
            // AI-NOTE: Add specific validation rules based on business requirements
          }

          /**
           * Execute the __USE_CASE_NAME_LOWER_CASE__ operation
           * Orchestrates the use case flow with minimal business logic
           * @param input - Input parameters from domain
           * @returns Promise with domain output
           * @throws Domain errors on business rule violations
           */
          async execute(input: __USE_CASE_NAME_PASCAL_CASE__Input): Promise<__USE_CASE_NAME_PASCAL_CASE__Output> {
            // AI-NOTE: Minimal orchestration logic only
            // Business rules should be in domain layer

            // Step 1: Validate input
            this.validateInput(input)

            // Step 2: Prepare data for repository
            const repositoryData = {
              __INPUT_FIELD_1__: input.__INPUT_FIELD_1__,
              __INPUT_FIELD_2__: input.__INPUT_FIELD_2__,
              __INPUT_FIELD_3__: input.__INPUT_FIELD_3__
            }

            // Step 3: Call repository (infrastructure abstraction)
            const result = await this.__FEATURE_NAME_CAMEL_CASE__Repository.__REPOSITORY_METHOD_NAME__(repositoryData)

            // Step 4: Map to domain output
            const output: __USE_CASE_NAME_PASCAL_CASE__Output = {
              __OUTPUT_FIELD_1__: result.__OUTPUT_FIELD_1__ || result.id,
              __OUTPUT_FIELD_2__: result.__OUTPUT_FIELD_2__ || result.__INPUT_FIELD_2__,
              __OUTPUT_FIELD_3__: result.__OUTPUT_FIELD_3__ || result.__INPUT_FIELD_3__,
              __TIMESTAMP_FIELD__: result.createdAt || new Date()
            }

            return output
          }
        }
      validation_script: |
        echo "üü¢ Running TDD GREEN phase - making tests pass..."

        # Run the tests - they should pass now
        npm run test -- src/features/__FEATURE_NAME_KEBAB_CASE__/__USE_CASE_NAME_KEBAB_CASE__/data/usecases/db-__USE_CASE_NAME_KEBAB_CASE__.spec.ts

        if [ $? -eq 0 ]; then
          echo "‚úÖ GREEN phase complete - all tests passing!"
        else
          echo "‚ùå Tests still failing - implementation needs adjustment"
          echo "   Review the test failures and adjust implementation"
          exit 1
        fi

        # Lint check
        npm run lint -- src/features/__FEATURE_NAME_KEBAB_CASE__/__USE_CASE_NAME_KEBAB_CASE__/data

        git add .
        git commit -m "feat(data): implement __USE_CASE_NAME_KEBAB_CASE__ data layer (TDD GREEN phase)"

    # === STEP 6: REFACTOR AND OPTIMIZE (TDD REFACTOR PHASE) ===
    - id: 'refactor-data-implementation-__USE_CASE_NAME_KEBAB_CASE__'
      type: 'validation'
      description: 'Refactor data implementation while keeping tests green (TDD REFACTOR)'
      status: 'PENDING'
      rlhf_score: null
      execution_log: ''
      references:
        - type: 'internal_guideline'
          source: 'TESTING_GUIDE.md'
          description: 'TDD Refactor phase - improve code while keeping tests green.'
      run_scripts:
        description: 'Refactor and validate data implementation'
        scripts:
          - name: 'Run all data layer tests'
            command: |
              echo "‚ôªÔ∏è  TDD REFACTOR phase - improving code quality..."

              # Ensure tests still pass after any refactoring
              npm run test -- src/features/__FEATURE_NAME_KEBAB_CASE__/__USE_CASE_NAME_KEBAB_CASE__/data

              if [ $? -eq 0 ]; then
                echo "‚úÖ Tests still passing after refactoring"
              else
                echo "‚ùå Refactoring broke tests - please fix"
                exit 1
              fi
            workingDirectory: '__PROJECT_NAME__'

          - name: 'Check test coverage'
            command: |
              echo "üìä Checking test coverage for data layer..."

              npm run test:coverage -- src/features/__FEATURE_NAME_KEBAB_CASE__/__USE_CASE_NAME_KEBAB_CASE__/data

              echo "‚úÖ Coverage report generated"
            workingDirectory: '__PROJECT_NAME__'

          - name: 'Final commit'
            command: |
              git add .
              git commit -m "refactor(data): optimize __USE_CASE_NAME_KEBAB_CASE__ implementation (TDD REFACTOR phase)" || echo "No changes to commit"
            workingDirectory: '__PROJECT_NAME__'

    # === STEP 7: CREATE REPOSITORY IMPLEMENTATION (IF NEEDED) ===
    - id: 'create-repository-implementation-__USE_CASE_NAME_KEBAB_CASE__'
      type: 'conditional_file'
      description: 'Create repository implementation in feature shared infra'
      condition: 'check_if_new_repository_implementation_needed'
      status: 'PENDING'
      rlhf_score: null
      execution_log: ''
      references:
        - type: 'external_pattern'
          source: 'context7'
          query: 'prisma repository pattern typescript'
          url: 'https://github.com/...'
          description: 'Repository implementation with Prisma ORM.'
      path: '__PROJECT_NAME__/src/features/__FEATURE_NAME_KEBAB_CASE__/shared/infra/db/prisma-__FEATURE_NAME_KEBAB_CASE__-repository.ts'
      template: |
        import { PrismaClient } from '@prisma/client'
        // Import the protocol from data layer
        // import { __REPOSITORY_PROTOCOL_NAME__ } from '../../__USE_CASE_NAME_KEBAB_CASE__/data/protocols/__REPOSITORY_PROTOCOL_NAME__'

        /**
         * Prisma implementation of __FEATURE_NAME_PASCAL_CASE__ repository
         * Handles database operations using Prisma ORM with transaction support
         * @layer Infrastructure Layer
         * @pattern Repository Pattern
         * @implements __REPOSITORY_PROTOCOL_NAME__
         */
        export class Prisma__FEATURE_NAME_PASCAL_CASE__Repository {
          constructor(
            private readonly prisma: PrismaClient
          ) {}

          /**
           * __REPOSITORY_METHOD_DESCRIPTION__
           * @param data - Data to persist
           * @param tx - Optional Prisma transaction client for atomic operations
           * @returns Promise with persisted entity
           */
          async __REPOSITORY_METHOD_NAME__(
            data: any,
            tx?: Omit<PrismaClient, '$connect' | '$disconnect' | '$on' | '$transaction' | '$use'>
          ): Promise<any> {
            // AI-NOTE: Use transaction client if provided, otherwise use main client
            const client = tx || this.prisma

            const result = await client.__MODEL_NAME__.create({
              data: {
                __INPUT_FIELD_1__: data.__INPUT_FIELD_1__,
                __INPUT_FIELD_2__: data.__INPUT_FIELD_2__,
                __INPUT_FIELD_3__: data.__INPUT_FIELD_3__
              }
            })

            return {
              id: result.id,
              __OUTPUT_FIELD_1__: result.__OUTPUT_FIELD_1__,
              __OUTPUT_FIELD_2__: result.__OUTPUT_FIELD_2__,
              __OUTPUT_FIELD_3__: result.__OUTPUT_FIELD_3__,
              createdAt: result.createdAt,
              updatedAt: result.updatedAt
            }
          }

          /**
           * Execute operations within a transaction for data consistency
           * @param fn - Function to execute within transaction
           * @returns Promise with transaction result
           */
          async executeInTransaction<T>(
            fn: (tx: Omit<PrismaClient, '$connect' | '$disconnect' | '$on' | '$transaction' | '$use'>) => Promise<T>
          ): Promise<T> {
            return await this.prisma.$transaction(fn)
          }
        }

    # === STEP 8: INTEGRATION TEST FOR DATA LAYER ===
    - id: 'create-data-integration-test-__USE_CASE_NAME_KEBAB_CASE__'
      type: 'create_file'
      description: 'Create integration test for data layer with real dependencies'
      status: 'PENDING'
      rlhf_score: null
      execution_log: ''
      references:
        - type: 'internal_guideline'
          source: 'TESTING_GUIDE.md'
          description: 'Integration testing for data layer.'
      path: '__PROJECT_NAME__/src/features/__FEATURE_NAME_KEBAB_CASE__/__USE_CASE_NAME_KEBAB_CASE__/__tests__/integration/db-__USE_CASE_NAME_KEBAB_CASE__.test.ts'
      template: |
        import { Db__USE_CASE_NAME_PASCAL_CASE__ } from '../../data/usecases/db-__USE_CASE_NAME_KEBAB_CASE__'
        import { Prisma__FEATURE_NAME_PASCAL_CASE__Repository } from '../../../shared/infra/db/prisma-__FEATURE_NAME_KEBAB_CASE__-repository'
        import { PrismaClient } from '@prisma/client'

        /**
         * Integration test for Db__USE_CASE_NAME_PASCAL_CASE__
         * Tests with real repository implementation
         * @layer Integration Tests
         * @pattern Integration Testing
         */
        describe('Db__USE_CASE_NAME_PASCAL_CASE__ Integration', () => {
          let prisma: PrismaClient
          let repository: Prisma__FEATURE_NAME_PASCAL_CASE__Repository
          let sut: Db__USE_CASE_NAME_PASCAL_CASE__

          beforeAll(async () => {
            // Setup test database connection
            prisma = new PrismaClient({
              datasources: {
                db: {
                  url: process.env.DATABASE_TEST_URL
                }
              }
            })
            await prisma.$connect()
          })

          afterAll(async () => {
            // Cleanup and disconnect
            await prisma.__MODEL_NAME__.deleteMany({})
            await prisma.$disconnect()
          })

          beforeEach(async () => {
            // Clear data before each test
            await prisma.__MODEL_NAME__.deleteMany({})

            // Setup SUT with real dependencies
            repository = new Prisma__FEATURE_NAME_PASCAL_CASE__Repository(prisma)
            sut = new Db__USE_CASE_NAME_PASCAL_CASE__(repository)
          })

          test('Should create and return __FEATURE_NAME_LOWER_CASE__ with real database', async () => {
            // Arrange
            const input = {
              __INPUT_FIELD_1__: 'integration_value_1',
              __INPUT_FIELD_2__: 'integration_value_2',
              __INPUT_FIELD_3__: 'integration_value_3'
            }

            // Act
            const output = await sut.execute(input)

            // Assert
            expect(output).toBeTruthy()
            expect(output.__OUTPUT_FIELD_1__).toBeTruthy()
            expect(output.__TIMESTAMP_FIELD__).toBeInstanceOf(Date)

            // Verify in database
            const dbRecord = await prisma.__MODEL_NAME__.findFirst({
              where: { __OUTPUT_FIELD_1__: output.__OUTPUT_FIELD_1__ }
            })
            expect(dbRecord).toBeTruthy()
          })
        })
      validation_script: |
        echo "üß™ Running integration tests for data layer..."

        # Run integration tests if database is available
        if [ -n "$DATABASE_TEST_URL" ]; then
          npm run test:integration -- src/features/__FEATURE_NAME_KEBAB_CASE__/__USE_CASE_NAME_KEBAB_CASE__/__tests__/integration

          if [ $? -eq 0 ]; then
            echo "‚úÖ Integration tests passing"
          else
            echo "‚ö†Ô∏è  Integration tests failed - check database connection"
          fi
        else
          echo "‚è≠Ô∏è  Skipping integration tests - DATABASE_TEST_URL not set"
        fi

        git add .
        git commit -m "test(data): add integration tests for __USE_CASE_NAME_KEBAB_CASE__"

    # === STEP 9: CREATE PULL REQUEST ===
    - id: 'create-pull-request-data-__USE_CASE_NAME_KEBAB_CASE__'
      type: 'validation'
      description: 'Create pull request for __USE_CASE_NAME_PASCAL_CASE__ data implementation'
      status: 'PENDING'
      rlhf_score: null
      execution_log: ''
      references:
        - type: 'internal_guideline'
          source: 'PR_TEMPLATE.md'
          description: 'Pull request template and review checklist for data layer'
      run_scripts:
        description: 'Push branch and create pull request for data layer'
        scripts:
          - name: 'Push and create data PR'
            command: |
              BRANCH_NAME="feat/__USE_CASE_NAME_KEBAB_CASE__-data-layer"

              # Push the branch
              git push -u origin "$BRANCH_NAME" || {
                echo "‚ùå Failed to push branch to remote"
                exit 1
              }

              # Create PR using GitHub CLI if available
              if command -v gh &> /dev/null; then
                gh pr create \
                  --title "feat(__USE_CASE_NAME_KEBAB_CASE__): implement data layer with TDD" \
                  --body "## Summary

                Implements data layer for __USE_CASE_NAME_PASCAL_CASE__ use case following Clean Architecture and TDD methodology.

                ## Data Layer Components Implemented
                - ‚úÖ **Use Case Implementation**: Db__USE_CASE_NAME_PASCAL_CASE__ with dependency injection
                - ‚úÖ **Repository Protocol**: Abstract interface for database operations
                - ‚úÖ **Repository Implementation**: Prisma-based concrete implementation
                - ‚úÖ **Input Validation**: Data integrity and business rule validation
                - ‚úÖ **Error Handling**: Proper error propagation to domain layer
                - ‚úÖ **Integration Tests**: Tests with real database dependencies

                ## TDD Methodology Applied
                - üî¥ **RED**: Failing tests written first for data layer
                - üü¢ **GREEN**: Minimal implementation to make tests pass
                - ‚ôªÔ∏è  **REFACTOR**: Code optimization while maintaining test coverage

                ## Testing Strategy
                - [ ] Unit tests pass (>90% coverage)
                - [ ] Integration tests pass with real database
                - [ ] Error scenarios properly handled
                - [ ] Business rules validation working
                - [ ] Repository abstraction properly implemented

                ## Architecture Compliance
                - [ ] Dependency Inversion Principle followed
                - [ ] No business logic in data layer (orchestration only)
                - [ ] Proper separation between domain and infrastructure
                - [ ] Repository pattern correctly implemented
                - [ ] Input/output mapping between layers

                ## Performance & Reliability
                - [ ] Database operations optimized
                - [ ] Transaction support implemented
                - [ ] Proper error handling and logging
                - [ ] Input validation prevents invalid data

                ## Checklist
                - [ ] Code follows Clean Architecture principles
                - [ ] All tests pass with adequate coverage
                - [ ] Documentation is updated
                - [ ] No breaking changes introduced
                - [ ] Repository abstraction is properly defined
                - [ ] Error handling covers all edge cases" \
                  --assignee @me \
                  --label "enhancement,data-layer,clean-architecture,tdd"

                echo "‚úÖ Pull request created successfully"
              else
                echo "üìù Push successful. Please create PR manually at:"
                echo "   https://github.com/__GITHUB_ORG__/__PROJECT_NAME__/compare/$BRANCH_NAME"
              fi
            workingDirectory: '__PROJECT_NAME__'

    # === STEP 10: TRIGGER AI CODE REVIEW ===
    - id: 'trigger-ai-review-data-__USE_CASE_NAME_KEBAB_CASE__'
      type: 'validation'
      description: 'Trigger AI-powered code review with Claude for data layer'
      status: 'PENDING'
      rlhf_score: null
      execution_log: ''
      references:
        - type: 'external_pattern'
          source: 'claude-cli'
          query: 'claude code review data layer clean architecture'
          url: 'https://claude.ai/docs/code-review'
          description: 'AI-powered code review using Claude for data layer patterns'
      run_scripts:
        description: 'Run Claude AI code review on the data implementation'
        scripts:
          - name: 'Trigger Claude data review'
            command: |
              BRANCH_NAME="feat/__USE_CASE_NAME_KEBAB_CASE__-data-layer"

              # Check if Claude CLI is available
              if command -v claude &> /dev/null; then
                echo "ü§ñ Starting AI code review with Claude for data layer..."

                claude /review \
                  --branch "$BRANCH_NAME" \
                  --focus "clean-architecture,data-patterns,tdd,dependency-injection" \
                  --checklist ".github/data_review_checklist.md" \
                  --output "review-data-__USE_CASE_NAME_KEBAB_CASE__.md"

                echo "‚úÖ AI data review complete. Check review-data-__USE_CASE_NAME_KEBAB_CASE__.md"

                # Add review as PR comment if gh CLI is available
                if command -v gh &> /dev/null && [ -f "review-data-__USE_CASE_NAME_KEBAB_CASE__.md" ]; then
                  gh pr comment --body-file "review-data-__USE_CASE_NAME_KEBAB_CASE__.md"
                  echo "‚úÖ Review posted to PR"
                fi
              else
                echo "‚ö†Ô∏è  Claude CLI not installed. Skipping AI review."
                echo "   Install with: npm install -g @anthropic/claude-cli"
              fi
            workingDirectory: '__PROJECT_NAME__'

    # === STEP 11: POST-MERGE CLEANUP ===
    - id: 'post-merge-cleanup-data-__USE_CASE_NAME_KEBAB_CASE__'
      type: 'validation'
      description: 'Cleanup after data PR merge'
      status: 'PENDING'
      rlhf_score: null
      execution_log: ''
      references:
        - type: 'internal_guideline'
          source: 'GIT_WORKFLOW.md'
          description: 'Post-merge cleanup procedures for data layer'
      run_scripts:
        description: 'Clean up local and remote branches after data merge'
        scripts:
          - name: 'Post-merge data cleanup'
            command: |
              BRANCH_NAME="feat/__USE_CASE_NAME_KEBAB_CASE__-data-layer"

              # Check if PR is merged
              if command -v gh &> /dev/null; then
                PR_STATE=$(gh pr view "$BRANCH_NAME" --json state -q .state 2>/dev/null || echo "UNKNOWN")

                if [ "$PR_STATE" = "MERGED" ]; then
                  echo "üßπ Starting post-merge cleanup for data layer..."

                  # Switch to main branch
                  git checkout main || git checkout master
                  git pull origin main || git pull origin master

                  # Delete local branch
                  git branch -d "$BRANCH_NAME"

                  # Delete remote branch
                  git push origin --delete "$BRANCH_NAME"

                  # Clean up review files
                  rm -f review-data-__USE_CASE_NAME_KEBAB_CASE__.md

                  echo "‚úÖ Data cleanup complete. Branch deleted locally and remotely."
                else
                  echo "‚è≥ Data PR not yet merged. Skipping cleanup."
                fi
              else
                echo "‚ö†Ô∏è  GitHub CLI not available. Please clean up branches manually after merge."
              fi
            workingDirectory: '__PROJECT_NAME__'

# ============= END DATA STEPS BACKEND SECTION =============