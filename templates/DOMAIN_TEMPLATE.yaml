# AI-NOTE: This YAML file is the single source of truth for generating domain layers.
# When creating a feature implementation, you MUST adhere to the structure and rules defined here.
version: '3.0.0'
# AI-NOTE: Update these fields to describe the specific feature.
metadata:
  title: '__FEATURE_NAME_PASCAL_CASE__ Domain Layer - Clean Architecture'
  description: 'TDD template for __FEATURE_NAME_LOWER_CASE__ feature following the master template rules.'
  source: 'TODO_DOMAIN_TEMPLATE.yaml'
  # AI-NOTE: This should be replaced with the current date, e.g., YYYY-MM-DD.
  lastUpdated: '__CURRENT_DATE__'

# AI-NOTE: Replace __FEATURE_NAME_KEBAB_CASE__ with the feature name.
structure:
  basePath: 'src/features/__FEATURE_NAME_KEBAB_CASE__/domain'
  folders:
    - 'errors'      # Feature-specific errors
    - 'use-cases'   # Feature use case interfaces
    - 'test'        # Feature test helpers

# ------------------------------------------------------------------------------
# AI-NOTE: IMMUTABLE SECTIONS AHEAD.
# The sections from here until 'steps' are architectural rules.
# You MUST copy them verbatim into the implementation file without ANY modification.
# ------------------------------------------------------------------------------

layer_rules:
  can_import_from_domain:
    - 'Data Layer - Implements the use case interfaces'
    - 'Presentation Layer - Uses domain types and calls use cases'
    - 'Infrastructure Layer - May use domain types for adapters'
    - 'Main/Factory Layer - Wires everything together, knows all layers'
    - 'Test Files - Can import domain types and interfaces for testing'

  cannot_import_from_domain:
    - 'External Libraries - Should never know about domain'
    - 'Node Modules - Third-party code should not depend on domain'

  domain_cannot_import_from:
    - 'Any other layer - Domain must be completely independent'
    - 'Data Layer - No implementation details'
    - 'Presentation Layer - No UI concerns'
    - 'Infrastructure Layer - No external dependencies'
    - 'Main Layer - No dependency injection logic'
    - 'External Libraries - No third-party dependencies'

# Domain layer rules from templates/DOMAIN_TEMPLATES.md
domain_rules:
  allowed:
    - 'Simple type definitions (Input/Output types)'
    - 'Use case interfaces (contracts only)'
    - 'Domain-specific error classes'
    - 'Test mock functions'

  forbidden:
    - 'Framework dependencies (React, Next.js, Express)'
    - 'External libraries (axios, fetch, database clients)'
    - 'Implementation details of any kind'
    - 'UI components'
    - 'HTTP/Database/File system operations'
    - 'Environment variables'
    - 'Console.log or any I/O operations'
    - 'Value objects'
    - 'Entities'
    - 'Business rules or business logic'
    - 'Validation logic'
    - 'Calculations or computations'
    - 'Any behavior beyond type definitions and interfaces'

# Use case rules from templates/DOMAIN_TEMPLATES.md
use_case_rules:
  should:
    - 'Define only interfaces/contracts, not implementations'
    - 'Have EXACTLY ONE responsibility (one business operation)'
    - 'Do ONE thing and ONE thing only (never multiple operations)'
    - 'Return domain types or primitives'
    - 'Be named with verbs (CreateUser, AuthenticateUser, etc.)'
    - 'Be framework agnostic'

  should_not:
    - 'Contain implementation logic'
    - 'Know about HTTP, databases, or external services'
    - 'Import from data, presentation, or infrastructure layers'
    - 'Have side effects'
    - 'Execute multiple operations (e.g., CreateUserAndSendEmail is wrong)'

# Error rules from templates/DOMAIN_TEMPLATES.md
error_rules:
  should:
    - 'Extend the native Error class'
    - 'Have descriptive names ending with Error'
    - 'Contain meaningful error messages'
    - 'Represent business rule violations'
    - 'Be thrown when domain invariants are violated'

  should_not:
    - 'Contain HTTP status codes'
    - 'Include technical/implementation details'
    - 'Expose sensitive information'
    - 'Import external dependencies'

# Test helper rules from templates/DOMAIN_TEMPLATES.md
test_helper_rules:
  should:
    - 'Create mock/stub implementations of use cases'
    - 'Generate fake test data'
    - 'Be pure functions that return consistent data'
    - 'Help reduce test boilerplate'
    - 'Use ONLY Vitest (Jest is prohibited)'

  should_not:
    - 'Make real API calls or database queries'
    - 'Depend on external services'
    - 'Contain test assertions (those belong in test files)'
    - 'Have side effects or maintain state'
    - 'Use Jest (use Vitest instead)'

# ------------------------------------------------------------------------------
# AI-NOTE: DYNAMIC IMPLEMENTATION SECTION.
# Replicate the generic steps below for each use case, error, and test helper
# required by the feature, replacing the placeholder variables (e.g., __FEATURE_NAME_KEBAB_CASE__).
# ------------------------------------------------------------------------------

steps:
  - id: 'create-feature-branch'
    type: 'branch'
    description: 'Create a new feature branch for __FEATURE_NAME_PASCAL_CASE__'
    status: 'PENDING' # PENDING | SUCCESS | FAILED | SKIPPED
    rlhf_score: null # -2, -1, 0, 1, 2
    execution_log: ''
    references:
      - type: 'internal_guideline'
        source: 'GIT_WORKFLOW.md'
        description: 'Following git branching best practices for feature development.'
    action:
      branch_name: 'feat/__FEATURE_NAME_KEBAB_CASE__-domain'
    validation_script: |
      echo "üåø Creating feature branch..."
      # Check if we are on a clean state
      if [ -n "$(git status --porcelain)" ]; then
        echo "‚ö†Ô∏è Warning: You have uncommitted changes. Stashing them..."
        git stash save "Auto-stash before creating feature branch for __FEATURE_NAME_KEBAB_CASE__"
      fi

      # Get current branch to use as base
      CURRENT_BRANCH=$(git branch --show-current)
      echo "üìç Current branch: $CURRENT_BRANCH"

      # Create and checkout new feature branch
      BRANCH_NAME="feat/__FEATURE_NAME_KEBAB_CASE__-domain"

      # Check if branch already exists
      if git show-ref --quiet refs/heads/$BRANCH_NAME; then
        echo "‚ö†Ô∏è Branch $BRANCH_NAME already exists. Checking out..."
        git checkout $BRANCH_NAME
      else
        echo "üåø Creating new branch: $BRANCH_NAME"
        git checkout -b $BRANCH_NAME
      fi

      # Verify we're on the correct branch
      CURRENT=$(git branch --show-current)
      if [ "$CURRENT" != "$BRANCH_NAME" ]; then
        echo "‚ùå ERROR: Failed to switch to branch $BRANCH_NAME"
        exit 1
      fi

      echo "‚úÖ Successfully created and switched to branch: $BRANCH_NAME"

      # If we had stashed changes, inform the user
      if git stash list | grep -q "Auto-stash before creating feature branch"; then
        echo "üí° Note: You have stashed changes. Run 'git stash pop' to restore them if needed."
      fi

  - id: 'create-structure'
    type: 'folder'
    description: 'Create domain folder structure'
    status: 'PENDING' # PENDING | SUCCESS | FAILED | SKIPPED
    rlhf_score: null # -2, -1, 0, 1, 2
    execution_log: ''
    # AI-NOTE: 'references' for this step can be left empty or link to architectural decision records.
    references:
      - type: 'internal_guideline'
        source: 'ARCHITECTURE.md'
        description: 'Following the standard feature-based domain structure.'
    action:
      create_folders:
        basePath: 'src/features/__FEATURE_NAME_KEBAB_CASE__/domain'
        folders:
          - 'errors'
          - 'use-cases'
          - 'test'
    validation_script: |
      echo "‚úÖ Verifying folder structure..."
      # Adiciona uma verifica√ß√£o expl√≠cita para falhar se as pastas n√£o existirem
      if [ ! -d "src/features/__FEATURE_NAME_KEBAB_CASE__/domain/errors" ] || \
         [ ! -d "src/features/__FEATURE_NAME_KEBAB_CASE__/domain/use-cases" ] || \
         [ ! -d "src/features/__FEATURE_NAME_KEBAB_CASE__/domain/test" ]; then
        echo "‚ùå ERROR: One or more domain folders were not created."
        exit 1
      fi
      echo "‚úÖ Folders exist."

  # Step 2: Create first use case
  - id: 'create-use-case-__ACTION_ENTITY_KEBAB_CASE__'
    type: 'create_file'
    description: 'Create __ACTION_ENTITY_PASCAL_CASE__ use case interface'
    status: 'PENDING' # PENDING | SUCCESS | FAILED | SKIPPED
    rlhf_score: null # -2, -1, 0, 1, 2
    execution_log: ''
    # AI-NOTE: For each step, you MUST populate this 'references' section.
    # Use 'context7' for external design patterns and 'serena' for internal codebase analysis.
    references:
      - type: 'external_pattern' # 'external_pattern' or 'internal_code_analysis'
        source: 'context7'
        query: 'awesome system design __CONCEPT__'
        url: 'https://github.com/...' # Link direto para a fonte que inspirou o design
        description: 'This use case follows the Command pattern for handling actions.'
      - type: 'internal_code_analysis'
        source: 'serena'
        tool: 'find_symbol'
        query: '*Repository'
        description: 'The structure is consistent with existing use cases like `OtherUseCase` found in the project.'
    path: 'src/features/__FEATURE_NAME_KEBAB_CASE__/domain/use-cases/__ACTION_ENTITY_KEBAB_CASE__.ts'
    template: |
      /**
       * Input parameters for __ACTION_ENTITY_PASCAL_CASE__UseCase
       */
      export type __ACTION_ENTITY_PASCAL_CASE__Input = {
        __USE_CASE_INPUT_FIELDS__
      }

      /**
       * Output type for __ACTION_ENTITY_PASCAL_CASE__UseCase
       */
      export type __ACTION_ENTITY_PASCAL_CASE__Output = {
        __USE_CASE_OUTPUT_FIELDS__
      }

      /**
       * __ACTION_ENTITY_PASCAL_CASE__UseCase interface
       * @description __USE_CASE_DESCRIPTION__
       */
      export interface __ACTION_ENTITY_PASCAL_CASE__UseCase {
        /**
         * Execute the __ACTION_ENTITY_LOWER_CASE__ operation
         * @param input - The input parameters
         * @returns Promise with the operation output
         */
        execute: (input: __ACTION_ENTITY_PASCAL_CASE__Input) => Promise<__ACTION_ENTITY_PASCAL_CASE__Output>
      }
    validation_script: |
      # AI-NOTE: This script is immutable. Only the commit message placeholder is replaced.
      echo "üîç Running lint check..."
      yarn lint
      if [ $? -ne 0 ]; then
        echo "‚ùå LINT FAILED - Attempting auto-fix..."
        yarn lint --fix
        if [ $? -ne 0 ]; then
          echo "‚ùå AUTO-FIX FAILED - Manual intervention required"
          echo "üìã Run 'yarn lint' to see remaining errors"
          exit 1
        fi
        echo "‚úÖ Lint errors auto-fixed, validating again..."
        yarn lint
        if [ $? -ne 0 ]; then
          echo "‚ùå LINT STILL FAILING - Manual fixes needed"
          exit 1
        fi
      fi
      echo "‚úÖ Lint passed"

      echo "üß™ Running tests with coverage..."
      yarn test --coverage
      if [ $? -ne 0 ]; then
        echo "‚ùå TESTS FAILED - Running specific test to identify issue..."
        yarn test --run --reporter=verbose
        echo "‚ùå Tests must be fixed manually"
        echo "üìã Check the test output above for details"
        exit 1
      fi
      echo "‚úÖ Tests passed"

      echo "üì¶ Staging changes..."
      git add .

      echo "üíæ Creating commit..."
      git commit -m "feat(__FEATURE_NAME_KEBAB_CASE__): add __ACTION_ENTITY_KEBAB_CASE__ use case"
      if [ $? -ne 0 ]; then
        echo "‚ùå COMMIT FAILED - Checking git status..."
        git status
        echo "üìã Review the status above and fix any issues"
        exit 1
      fi
      echo "‚úÖ Successfully committed"

  # Step 3: Create error class
  - id: 'create-error-__ERROR_NAME_KEBAB_CASE__'
    type: 'create_file'
    description: 'Create __ERROR_NAME_KEBAB_CASE__ domain error'
    status: 'PENDING' # PENDING | SUCCESS | FAILED | SKIPPED
    rlhf_score: null # -2, -1, 0, 1, 2
    execution_log: ''
    # AI-NOTE: For each step, you MUST populate this 'references' section.
    # Use 'context7' for external design patterns and 'serena' for internal codebase analysis.
    references:
      - type: 'external_pattern' # 'external_pattern' or 'internal_code_analysis'
        source: 'context7'
        query: 'awesome system design __CONCEPT__'
        url: 'https://github.com/...' # Link direto para a fonte que inspirou o design
        description: 'This use case follows the Command pattern for handling actions.'
      - type: 'internal_code_analysis'
        source: 'serena'
        tool: 'find_symbol'
        query: '*Repository'
        description: 'The structure is consistent with existing use cases like `OtherUseCase` found in the project.'
    path: 'src/features/__FEATURE_NAME_KEBAB_CASE__/domain/errors/__ERROR_NAME_KEBAB_CASE__.ts'
    template: |
      /**
       * Error thrown when __ERROR_DESCRIPTION__
       * @extends Error
       */
      export class __ERROR_NAME_PASCAL_CASE__Error extends Error {
        constructor() {
          super('__ERROR_MESSAGE__')
          this.name = '__ERROR_NAME_PASCAL_CASE__Error'
        }
      }
    validation_script: |
      echo "üîç Running lint check..."
      yarn lint
      if [ $? -ne 0 ]; then
        echo "‚ùå LINT FAILED - Attempting auto-fix..."
        yarn lint --fix
        if [ $? -ne 0 ]; then
          echo "‚ùå AUTO-FIX FAILED - Manual intervention required"
          echo "üìã Run 'yarn lint' to see remaining errors"
          exit 1
        fi
        echo "‚úÖ Lint errors auto-fixed, validating again..."
        yarn lint
        if [ $? -ne 0 ]; then
          echo "‚ùå LINT STILL FAILING - Manual fixes needed"
          exit 1
        fi
      fi
      echo "‚úÖ Lint passed"

      echo "üß™ Running tests with coverage..."
      yarn test --coverage
      if [ $? -ne 0 ]; then
        echo "‚ùå TESTS FAILED - Running specific test to identify issue..."
        yarn test --run --reporter=verbose
        echo "‚ùå Tests must be fixed manually"
        echo "üìã Check the test output above for details"
        exit 1
      fi
      echo "‚úÖ Tests passed"

      echo "üì¶ Staging changes..."
      git add .

      echo "üíæ Creating commit..."
      git commit -m "feat(__FEATURE_NAME_KEBAB_CASE__): add __ERROR_NAME_KEBAB_CASE__ domain error"
      if [ $? -ne 0 ]; then
        echo "‚ùå COMMIT FAILED - Checking git status..."
        git status
        echo "üìã Review the status above and fix any issues"
        exit 1
      fi
      echo "‚úÖ Successfully committed"

  # Step 4: Create test helper
  - id: 'create-test-helper-__ACTION_ENTITY_KEBAB_CASE__'
    type: 'create_file'
    description: 'Create mock for __ACTION_ENTITY_PASCAL_CASE__ use case'
    status: 'PENDING' # PENDING | SUCCESS | FAILED | SKIPPED
    rlhf_score: null # -2, -1, 0, 1, 2
    execution_log: ''
    # AI-NOTE: For each step, you MUST populate this 'references' section.
    # Use 'context7' for external design patterns and 'serena' for internal codebase analysis.
    references:
      - type: 'external_pattern' # 'external_pattern' or 'internal_code_analysis'
        source: 'context7'
        query: 'awesome system design __CONCEPT__'
        url: 'https://github.com/...' # Link direto para a fonte que inspirou o design
        description: 'This use case follows the Command pattern for handling actions.'
      - type: 'internal_code_analysis'
        source: 'serena'
        tool: 'find_symbol'
        query: '*Repository'
        description: 'The structure is consistent with existing use cases like `OtherUseCase` found in the project.'
    path: 'src/features/__FEATURE_NAME_KEBAB_CASE__/domain/test/mock-__ACTION_ENTITY_KEBAB_CASE__-use-case.ts'
    template: |
      import { vi } from 'vitest'
      import type { __ACTION_ENTITY_PASCAL_CASE__UseCase, __ACTION_ENTITY_PASCAL_CASE__Input, __ACTION_ENTITY_PASCAL_CASE__Output } from '../use-cases/__ACTION_ENTITY_KEBAB_CASE__'

      /**
       * Creates a mock instance of __ACTION_ENTITY_PASCAL_CASE__Input
       * @returns Mock input for testing
       */
      export const mock__ACTION_ENTITY_PASCAL_CASE__Input = (): __ACTION_ENTITY_PASCAL_CASE__Input => ({
        __MOCK_INPUT_DATA__
      })

      /**
       * Creates a mock instance of __ACTION_ENTITY_PASCAL_CASE__Output
       * @returns Mock output for testing
       */
      export const mock__ACTION_ENTITY_PASCAL_CASE__Output = (): __ACTION_ENTITY_PASCAL_CASE__Output => ({
        __MOCK_OUTPUT_DATA__
      })

      /**
       * Creates a mock instance of __ACTION_ENTITY_PASCAL_CASE__UseCase
       * @returns Mocked use case with vitest functions
       */
      export const mock__ACTION_ENTITY_PASCAL_CASE__UseCase = (): __ACTION_ENTITY_PASCAL_CASE__UseCase => ({
        execute: vi.fn()
      })
    validation_script: |
      echo "üîç Running lint check..."
      yarn lint
      if [ $? -ne 0 ]; then
        echo "‚ùå LINT FAILED - Attempting auto-fix..."
        yarn lint --fix
        if [ $? -ne 0 ]; then
          echo "‚ùå AUTO-FIX FAILED - Manual intervention required"
          echo "üìã Run 'yarn lint' to see remaining errors"
          exit 1
        fi
        echo "‚úÖ Lint errors auto-fixed, validating again..."
        yarn lint
        if [ $? -ne 0 ]; then
          echo "‚ùå LINT STILL FAILING - Manual fixes needed"
          exit 1
        fi
      fi
      echo "‚úÖ Lint passed"

      echo "üß™ Running tests with coverage..."
      yarn test --coverage
      if [ $? -ne 0 ]; then
        echo "‚ùå TESTS FAILED - Running specific test to identify issue..."
        yarn test --run --reporter=verbose
        echo "‚ùå Tests must be fixed manually"
        echo "üìã Check the test output above for details"
        exit 1
      fi
      echo "‚úÖ Tests passed"

      echo "üì¶ Staging changes..."
      git add .

      echo "üíæ Creating commit..."
      git commit -m "test(__FEATURE_NAME_KEBAB_CASE__): add __ACTION_ENTITY_KEBAB_CASE__ use case test helpers"
      if [ $? -ne 0 ]; then
        echo "‚ùå COMMIT FAILED - Checking git status..."
        git status
        echo "üìã Review the status above and fix any issues"
        exit 1
      fi
      echo "‚úÖ Successfully committed"

  # OPTIONAL STEP: You can add more steps here for additional use cases, errors, or test helpers as needed.
  - id: 'refactor-__FILE_TO_MODIFY_KEBAB_CASE__'
    type: 'refactor_file'
    description: 'Refactor __FILE_TO_MODIFY_PASCAL_CASE__ to incorporate new logic'
    status: 'pending'
    rlhf_score: null
    execution_log: ''
    references:
      - type: 'internal_code_analysis'
        source: 'serena'
        tool: 'find_referencing_symbols'
        query: '__SYMBOL_BEING_CHANGED__'
        description: 'Refactoring this file because it is a primary consumer of the changed `__SYMBOL__` interface.'
    path: 'src/features/__FEATURE_NAME_KEBAB_CASE__/path/to/__FILE_TO_MODIFY_KEBAB_CASE__.ts'
    # O 'template' aqui n√£o √© o conte√∫do completo do arquivo,
    # mas sim um "diff" no formato que voc√™ sugeriu.
    template: |
      <<<REPLACE>>>
      // C√≥digo antigo que a IA identificou para ser substitu√≠do
      export type OldType = {
        fieldA: string;
      }
      <<</REPLACE>>>
      <<<WITH>>>
      // Novo c√≥digo que a IA gerou para substituir o antigo
      export type OldType = {
        fieldA: string;
        newFieldB: number; // Adicionando o novo campo
      }
      <<</WITH>>>
    validation_script: |
      echo "üîç Running lint check..."
      yarn lint
      if [ $? -ne 0 ]; then
        echo "‚ùå LINT FAILED - Attempting auto-fix..."
        yarn lint --fix
        if [ $? -ne 0 ]; then
          echo "‚ùå AUTO-FIX FAILED - Manual intervention required"
          echo "üìã Run 'yarn lint' to see remaining errors"
          exit 1
        fi
        echo "‚úÖ Lint errors auto-fixed, validating again..."
        yarn lint
        if [ $? -ne 0 ]; then
          echo "‚ùå LINT STILL FAILING - Manual fixes needed"
          exit 1
        fi
      fi
      echo "‚úÖ Lint passed"

      echo "üß™ Running tests with coverage..."
      yarn test --coverage
      if [ $? -ne 0 ]; then
        echo "‚ùå TESTS FAILED - Running specific test to identify issue..."
        yarn test --run --reporter=verbose
        echo "‚ùå Tests must be fixed manually"
        echo "üìã Check the test output above for details"
        exit 1
      fi
      echo "‚úÖ Tests passed"

      echo "üì¶ Staging changes..."
      git add .

      echo "üíæ Creating commit..."
      git commit -m "refactor(__FEATURE_NAME_KEBAB_CASE__): refactor __FILE_TO_MODIFY_KEBAB_CASE__"
      if [ $? -ne 0 ]; then
        echo "‚ùå COMMIT FAILED - Checking git status..."
        git status
        echo "üìã Review the status above and fix any issues"
        exit 1
      fi
      echo "‚úÖ Successfully committed"

  # AI-NOTE: This step is used by the AI during the self-correction loop.
  # When a 'create_file' step fails, the AI can generate an instance of this
  # step to delete the broken artifact before attempting a fix.
  - id: 'delete-file-__FILE_TO_DELETE_KEBAB_CASE__'
    type: 'delete_file'
    description: 'Delete the file __FILE_TO_DELETE_PASCAL_CASE__ due to a generation error'
    status: 'pending'
    rlhf_score: null
    execution_log: ''
    references:
      - type: 'internal_correction'
        source: 'self'
        description: 'Deleting the artifact from the failed step `__FAILED_STEP_ID__` to prepare for a corrected version.'
    path: 'src/features/__FEATURE_NAME_KEBAB_CASE__/path/to/__FILE_TO_DELETE_KEBAB_CASE__.ts'
    # AI-NOTE: The validation_script for a delete action should verify the file is gone
    # and then perform the standard quality checks before committing the deletion.
    validation_script: |
      echo "üóëÔ∏è Verifying file deletion..."
      if [ -f "src/features/__FEATURE_NAME_KEBAB_CASE__/path/to/__FILE_TO_DELETE_KEBAB_CASE__.ts" ]; then
        echo "‚ùå ERROR: File at __FILE_TO_DELETE_KEBAB_CASE__.ts was not deleted."
        exit 1
      fi
      echo "‚úÖ File successfully deleted."

      echo "üîç Running lint check on the project..."
      yarn lint
      if [ $? -ne 0 ]; then
        echo "‚ùå LINT FAILED after deletion."
        exit 1
      fi
      echo "‚úÖ Lint passed."

      echo "üì¶ Staging changes..."
      git add .

      echo "üíæ Creating commit..."
      git commit -m "chore(__FEATURE_NAME_KEBAB_CASE__): delete broken artifact __FILE_TO_DELETE_KEBAB_CASE__"
      if [ $? -ne 0 ]; then
        echo "‚ùå COMMIT FAILED - Checking git status..."
        git status
        exit 1
      fi
      echo "‚úÖ Successfully committed deletion."

# ------------------------------------------------------------------------------
# AI-NOTE: IMMUTABLE DOCUMENTATION SECTIONS AHEAD.
# Copy these sections verbatim. The [placeholders] inside the commands
# are for HUMAN examples and MUST NOT be replaced by the AI.
# ------------------------------------------------------------------------------

troubleshooting:
  lint_fails:
    - 'DO NOT commit - Fix all lint errors first'
    - 'Check for unused imports'
    - 'Verify proper TypeScript types'
    - 'Ensure no console.log statements'
    - 'Run yarn lint --fix to auto-fix when possible'

  tests_fail:
    - 'DO NOT commit - All tests must pass'
    - 'Check if mocks match the actual interfaces'
    - 'Verify Input/Output types are correct'
    - 'Ensure test coverage meets requirements'
    - 'Run specific test: yarn test [test-file-path]'

  typescript_fails:
    - 'Check all type definitions match'
    - 'Ensure no missing imports'
    - 'Verify interface implementations are complete'
    - 'Run yarn tsc --noEmit to check types'

# Refactoring checklist from templates/DOMAIN_TEMPLATES.md
refactoring:
  before_refactoring: |
    # Check current status and differences
    echo "üìä Checking current changes..."
    git status
    git diff

    # Ensure clean working directory
    echo "‚úÖ Saving current work..."
    git stash save "WIP: before refactoring"

    # Create refactoring branch
    echo "üåø Creating refactor branch..."
    git checkout -b refactor/[feature-name]

    # Run tests to ensure starting point is stable
    echo "üß™ Validating current state..."
    yarn test --run
    if [ $? -ne 0 ]; then
      echo "‚ùå Tests failing before refactor - fix first!"
      exit 1
    fi
    echo "‚úÖ Ready to refactor"

  during_refactoring: |
    # After each change, check what was modified
    echo "üîç Reviewing changes..."
    git diff --stat
    git diff

    # Validate the change
    yarn lint && yarn test --run

    # Commit atomically
    git add -p  # Interactive staging to commit only related changes
    git commit -m "refactor([feature-name]): [specific change description]"

    # Show what was changed in the last commit
    git show --stat

  common_scenarios:
    - name: 'Splitting a use case'
      wrong_example: |
        interface CreateUserAndSendEmailUseCase {
          execute: (input: CreateUserAndSendEmailInput) => Promise<CreateUserAndSendEmailOutput>
        }
      correct_example: |
        interface CreateUserUseCase {
          execute: (input: CreateUserInput) => Promise<CreateUserOutput>
        }
        interface SendWelcomeEmailUseCase {
          execute: (input: SendWelcomeEmailInput) => Promise<SendWelcomeEmailOutput>
        }
      script: |
        # Split the combined use case into separate files
        # Update all imports and references
        # Run tests after each change

    - name: 'Renaming for clarity'
      script: |
        # 1. See all occurrences before changing
        echo "üîç Finding all occurrences of [OldName]..."
        grep -r "[OldName]" src/features/[feature-name]/

        # 2. Perform the rename
        echo "‚úèÔ∏è Renaming [OldName] to [NewName]..."
        # Update files...

        # 3. Review the changes
        echo "üìä Reviewing rename changes..."
        git diff --word-diff

        # 4. Validate nothing broke
        yarn lint && yarn test --run

        # 5. Check if rename is complete
        echo "üîç Ensuring no [OldName] remains..."
        grep -r "[OldName]" src/features/[feature-name]/
        if [ $? -eq 0 ]; then
          echo "‚ö†Ô∏è Warning: [OldName] still found in some files"
        fi

        # 6. Commit the rename
        git add .
        git commit -m "refactor([feature-name]): rename [OldName] to [NewName] for clarity"

        # 7. Show the final diff
        git show --stat

# Recovery steps from templates/DOMAIN_TEMPLATES.md
recovery:
  accidental_commit: |
    # Revert the last commit but keep changes
    git reset --soft HEAD~1

    # Fix the issues
    # ... make corrections ...

    # Re-run validation
    yarn lint
    yarn test --coverage

    # Commit again with fixed code
    git add .
    git commit -m "[original message] - fixed"

  domain_polluted: |
    # 1. Identify violations in domain
    echo "üîç Checking for domain violations..."
    git diff src/features/[feature-name]/domain/

    # Check for forbidden patterns
    echo "‚ö†Ô∏è Checking for business logic..."
    grep -r "class.*{.*calculate\|validate\|process" src/features/[feature-name]/domain/

    echo "‚ö†Ô∏è Checking for external dependencies..."
    grep -r "import.*axios\|fetch\|http" src/features/[feature-name]/domain/

    echo "‚ö†Ô∏è Checking for console logs..."
    grep -r "console\." src/features/[feature-name]/domain/

    # 2. Show what needs to be moved
    git diff src/features/[feature-name]/domain/ --name-only

    # 3. After moving code to proper layers
    echo "‚úÖ Validating domain is clean..."
    yarn lint
    yarn test --run

    # 4. Commit the cleanup
    git add .
    git diff --staged --stat
    git commit -m "refactor([feature-name]): remove business logic from domain layer"

# AI Guidelines from templates/DOMAIN_TEMPLATES.md
ai_guidelines:
  - 'Always validate before committing: Run lint first, Run tests second, Only commit if both pass'
  - 'If generation fails: Identify the specific error, Fix only that error, Re-run validation, Do NOT proceed until fixed'
  - 'Follow the principle: One use case = One file = One responsibility'
  - 'If tempted to add "And" in a use case name, split it'
  - 'When in doubt: Choose simplicity over complexity, Split rather than combine, Ask for clarification rather than assume'
  - 'MUST generate different case styles from the input names (e.g., "Add Item To Cart" becomes: PascalCase=AddItemToCart, kebab-case=add-item-to-cart, lower case=add item to cart).'
  - 'MUST replace ALL placeholder variables (like __FEATURE_NAME_KEBAB_CASE__) with actual values'
  - 'MUST NOT leave any placeholder variables in the final implementation'
  - 'MUST NOT replace any [placeholders] found inside documentation sections like refactoring or recovery' # Adicionar esta regra para clareza extra
  - 'MUST use vitest, NOT jest'
  - 'MUST follow all domain rules - no business logic, no external dependencies'

# ------------------------------------------------------------------------------
# AI-NOTE: TASK EVALUATION SECTION.
# After the entire execution is complete, this section will be populated by a
# human reviewer or an evaluation script.
# ------------------------------------------------------------------------------

evaluation:
  # AI-NOTE: This final_status will be 'SUCCESS' if all steps passed, or 'FAILED' if any step failed.
  final_status: 'PENDING' # PENDING | SUCCESS | FAILED
  # AI-NOTE: The final_rlhf_score is an overall score for the entire task, assigned by a human reviewer.
  final_rlhf_score: null # -2, -1, 0, 1, 2
  # AI-NOTE: The reviewer will add a summary of what went well and what could be improved.
  # This text is the primary source for future learning and template improvements.
  reviewer_summary: |
    - What went well:
      - ...
    - Areas for improvement:
      - ...
  # AI-NOTE: This section lists actionable suggestions for improving the master templates or prompts.
  # This is the key to the continuous learning loop.
  template_improvement_suggestions:
    - target_template: 'domain.template.yaml'
      target_step_id: 'create-use-case-__ACTION_ENTITY_KEBAB_CASE__'
      suggestion: 'The generated mock data was too simplistic. The template should be updated to include more realistic data generation.'
      priority: 'medium'