# AI-NOTE: This YAML file is the single source of truth for generating clean architecture layers.
# This is the MASTER TEMPLATE that will evolve to support all architectural layers.
# Currently supports: Domain Layer
# Future support: Application, Infrastructure, Presentation Layers
#
# INTELLIGENT RLHF SCORING SYSTEM:
# The system uses Reinforcement Learning from Human Feedback to score execution quality:
# -2: CATASTROPHIC - Architecture violations, incorrect REPLACE/WITH format in refactor steps
# -1: RUNTIME ERROR - Lint failures, test failures, git operation problems
#  0: LOW CONFIDENCE - System is uncertain, avoids hallucinations
# +1: GOOD - Task complete but missing architectural elements
# +2: PERFECT - Exceptional quality with Clean Architecture, DDD principles, ubiquitous language
#
# QUALITY INDICATORS FOR +2 SCORE:
# - Uses ubiquitous language terminology
# - Follows Domain-Driven Design principles
# - Applies Clean Architecture concepts
# - Implements patterns: Aggregate Root, Value Objects, Domain Events
# - Perfect branch naming convention
# - Comprehensive PR descriptions
#
version: '3.0.0'
# AI-NOTE: Update these fields to describe the specific feature and layers.
metadata:
  title: '__FEATURE_NAME_PASCAL_CASE__ Clean Architecture Implementation'
  description: 'Clean Architecture template for __FEATURE_NAME_LOWER_CASE__ feature following master template rules.'
  source: 'TEMPLATE.yaml'
  # AI-NOTE: This should be replaced with the current date, e.g., YYYY-MM-DD.
  lastUpdated: '__CURRENT_DATE__'
  # AI-NOTE: Specify which layers are being implemented
  layers:
    - 'domain'
    # Future layers will be added here:
    # - 'application'
    # - 'infrastructure'
    # - 'presentation'
  # AI-NOTE: Define ubiquitous language for +2 RLHF score
  ubiquitousLanguage:
    - term: '__ENTITY_NAME__'
      definition: '__ENTITY_DEFINITION_IN_BUSINESS_CONTEXT__'
    - term: '__VALUE_OBJECT_NAME__'
      definition: '__VALUE_OBJECT_BUSINESS_MEANING__'
    - term: '__DOMAIN_EVENT__'
      definition: '__EVENT_BUSINESS_SIGNIFICANCE__'

# AI-NOTE: Base structure that will be extended for each layer
structure:
  basePath: 'src/features/__FEATURE_NAME_KEBAB_CASE__'
  # Layer-specific folders will be defined in each layer section
  layers:
    domain:
      folders:
        - 'errors'      # Feature-specific errors
        - 'use-cases'   # Feature use case interfaces
        - 'test'        # Feature test helpers
    # Future layers structure:
    # application:
    #   folders:
    #     - 'use-cases'  # Use case implementations
    #     - 'services'   # Application services
    # infrastructure:
    #   folders:
    #     - 'repositories'  # Data persistence
    #     - 'adapters'      # External service adapters
    # presentation:
    #   folders:
    #     - 'controllers'   # HTTP/GraphQL controllers
    #     - 'validators'    # Input validation

# ------------------------------------------------------------------------------
# ARCHITECTURAL RULES SECTION
# These rules define the Clean Architecture boundaries and dependencies
# ------------------------------------------------------------------------------

architecture:
  # Dependency flow: Presentation ‚Üí Application ‚Üí Domain ‚Üê Infrastructure
  dependency_rules:
    domain:
      can_import_from: []  # Domain imports nothing
      cannot_import_from: ['application', 'infrastructure', 'presentation', 'external']
    # Future layer rules will be added here:
    # application:
    #   can_import_from: ['domain']
    #   cannot_import_from: ['infrastructure', 'presentation', 'external']
    # infrastructure:
    #   can_import_from: ['domain', 'application']
    #   cannot_import_from: ['presentation']
    # presentation:
    #   can_import_from: ['domain', 'application']
    #   cannot_import_from: ['infrastructure']

  # Clean Architecture principles
  principles:
    - "Independence: Business rules don't know about outside world"
    - "Testability: Business rules can be tested without UI, Database, Web Server, etc."
    - "Flexibility: UI, Database, and any external agency are plugins"
    - "Separation: Business rules are the core, everything else is detail"

# ------------------------------------------------------------------------------
# AI-NOTE: IMMUTABLE SECTIONS AHEAD.
# The sections from here until 'steps' are architectural rules.
# You MUST copy them verbatim into the implementation file without ANY modification.
#
# AUTOMATED LEARNING SYSTEM:
# The RLHF system automatically:
# - Tracks success/failure patterns across executions
# - Identifies common error types and their fixes
# - Applies improvements when confidence > 80%
# - Generates learning reports with actionable insights
# - Prevents hallucinations with score 0 for uncertain cases
# ------------------------------------------------------------------------------

# ------------------------------------------------------------------------------
# LAYER-SPECIFIC RULES
# Currently only Domain layer is implemented
# ------------------------------------------------------------------------------

# Domain layer rules
domain_rules:
  allowed:
    - 'Simple type definitions (Input/Output types)'
    - 'Use case interfaces (contracts only)'
    - 'Domain-specific error classes'
    - 'Test mock functions'

  forbidden:
    - 'Framework dependencies (React, Next.js, Express)'
    - 'External libraries (axios, fetch, database clients)'
    - 'Implementation details of any kind'
    - 'UI components'
    - 'HTTP/Database/File system operations'
    - 'Environment variables'
    - 'Console.log or any I/O operations'
    - 'Value objects'
    - 'Entities'
    - 'Business rules or business logic'
    - 'Validation logic'
    - 'Calculations or computations'
    - 'Any behavior beyond type definitions and interfaces'

# Use case rules
use_case_rules:
  should:
    - 'Define only interfaces/contracts, not implementations'
    - 'Have EXACTLY ONE responsibility (one business operation)'
    - 'Do ONE thing and ONE thing only (never multiple operations)'
    - 'Return domain types or primitives'
    - 'Be named with verbs (CreateUser, AuthenticateUser, etc.)'
    - 'Be framework agnostic'

  should_not:
    - 'Contain implementation logic'
    - 'Know about HTTP, databases, or external services'
    - 'Import from data, presentation, or infrastructure layers'
    - 'Have side effects'
    - 'Execute multiple operations (e.g., CreateUserAndSendEmail is wrong)'

# Error rules
error_rules:
  should:
    - 'Extend the native Error class'
    - 'Have descriptive names ending with Error'
    - 'Contain meaningful error messages'
    - 'Represent business rule violations'
    - 'Be thrown when domain invariants are violated'

  should_not:
    - 'Contain HTTP status codes'
    - 'Include technical/implementation details'
    - 'Expose sensitive information'
    - 'Import external dependencies'

# Test helper rules
test_helper_rules:
  should:
    - 'Create mock/stub implementations of use cases'
    - 'Generate fake test data'
    - 'Be pure functions that return consistent data'
    - 'Help reduce test boilerplate'
    - 'Use ONLY Vitest (Jest is prohibited)'

  should_not:
    - 'Make real API calls or database queries'
    - 'Depend on external services'
    - 'Contain test assertions (those belong in test files)'
    - 'Have side effects or maintain state'
    - 'Use Jest (use Vitest instead)'

# ------------------------------------------------------------------------------
# AI-NOTE: DYNAMIC IMPLEMENTATION SECTION.
# Replicate the generic steps below for each use case, error, and test helper
# required by the feature, replacing the placeholder variables (e.g., __FEATURE_NAME_KEBAB_CASE__).
# ------------------------------------------------------------------------------

# ------------------------------------------------------------------------------
# IMPLEMENTATION STEPS
# Steps for generating the architectural layers
# ------------------------------------------------------------------------------

steps:
  # === GIT WORKFLOW ===
  - id: 'create-feature-branch'
    type: 'branch'
    description: 'Create a new feature branch for __FEATURE_NAME_PASCAL_CASE__'
    status: 'PENDING' # PENDING | SUCCESS | FAILED | SKIPPED
    rlhf_score: null # -2, -1, 0, 1, 2
    execution_log: ''
    references:
      - type: 'internal_guideline'
        source: 'GIT_WORKFLOW.md'
        description: 'Following git branching best practices for feature development.'
    action:
      branch_name: 'feat/__FEATURE_NAME_KEBAB_CASE__'
    validation_script: |
      echo "üåø Creating feature branch..."
      # Check if we are on a clean state
      if [ -n "$(git status --porcelain)" ]; then
        echo "‚ö†Ô∏è Warning: You have uncommitted changes. Stashing them..."
        git stash save "Auto-stash before creating feature branch for __FEATURE_NAME_KEBAB_CASE__"
      fi

      # Get current branch to use as base
      CURRENT_BRANCH=$(git branch --show-current)
      echo "üìç Current branch: $CURRENT_BRANCH"

      # Create and checkout new feature branch
      BRANCH_NAME="feat/__FEATURE_NAME_KEBAB_CASE__"

      # Check if branch already exists
      if git show-ref --quiet refs/heads/$BRANCH_NAME; then
        echo "‚ö†Ô∏è Branch $BRANCH_NAME already exists. Checking out..."
        git checkout $BRANCH_NAME
      else
        echo "üåø Creating new branch: $BRANCH_NAME"
        git checkout -b $BRANCH_NAME
      fi

      # Verify we're on the correct branch
      CURRENT=$(git branch --show-current)
      if [ "$CURRENT" != "$BRANCH_NAME" ]; then
        echo "‚ùå ERROR: Failed to switch to branch $BRANCH_NAME"
        exit 1
      fi

      echo "‚úÖ Successfully created and switched to branch: $BRANCH_NAME"

      # If we had stashed changes, inform the user
      if git stash list | grep -q "Auto-stash before creating feature branch"; then
        echo "üí° Note: You have stashed changes. Run 'git stash pop' to restore them if needed."
      fi

  # === DOMAIN LAYER STRUCTURE ===
  - id: 'create-domain-structure'
    type: 'folder'
    description: 'Create domain layer folder structure'
    status: 'PENDING' # PENDING | SUCCESS | FAILED | SKIPPED
    rlhf_score: null # -2, -1, 0, 1, 2
    execution_log: ''
    references:
      - type: 'internal_guideline'
        source: 'ARCHITECTURE.md'
        description: 'Following Clean Architecture domain layer structure.'
    action:
      create_folders:
        basePath: 'src/features/__FEATURE_NAME_KEBAB_CASE__/domain'
        folders:
          - 'errors'
          - 'use-cases'
          - 'test'
    validation_script: |
      echo "‚úÖ Verifying domain folder structure..."
      # Verify all required folders exist
      if [ ! -d "src/features/__FEATURE_NAME_KEBAB_CASE__/domain/errors" ] || \
         [ ! -d "src/features/__FEATURE_NAME_KEBAB_CASE__/domain/use-cases" ] || \
         [ ! -d "src/features/__FEATURE_NAME_KEBAB_CASE__/domain/test" ]; then
        echo "‚ùå ERROR: One or more domain folders were not created."
        exit 1
      fi
      echo "‚úÖ Domain folders exist."

  # === DOMAIN LAYER: USE CASE ===
  - id: 'create-use-case-__ACTION_ENTITY_KEBAB_CASE__'
    type: 'create_file'
    description: 'Create __ACTION_ENTITY_PASCAL_CASE__ use case interface'
    status: 'PENDING' # PENDING | SUCCESS | FAILED | SKIPPED
    rlhf_score: null # -2, -1, 0, 1, 2
    execution_log: ''
    # AI-NOTE: For each step, you MUST populate this 'references' section.
    # Use 'context7' for external design patterns and 'serena' for internal codebase analysis.
    references:
      - type: 'external_pattern'
        source: 'context7'
        query: 'clean architecture use case'
        url: 'https://github.com/...' # Link with your research phase
        description: 'Following Clean Architecture use case pattern.'
      - type: 'internal_code_analysis'
        source: 'serena'
        tool: 'find_symbol'
        query: '*UseCase'
        description: 'Consistent with existing use case interfaces.'
    path: 'src/features/__FEATURE_NAME_KEBAB_CASE__/domain/use-cases/__ACTION_ENTITY_KEBAB_CASE__.ts'
    # AI-NOTE FOR +2 SCORE: Include domain concepts and ubiquitous language in comments
    # Use business terminology, not technical jargon
    # Reference Domain-Driven Design principles when applicable
    template: |
      /**
       * Input parameters for __ACTION_ENTITY_PASCAL_CASE__UseCase
       * Following Clean Architecture principles - pure domain types
       * @domainConcept __UBIQUITOUS_LANGUAGE_TERM__
       */
      export type __ACTION_ENTITY_PASCAL_CASE__Input = {
        __USE_CASE_INPUT_FIELDS__
      }

      /**
       * Output type for __ACTION_ENTITY_PASCAL_CASE__UseCase
       * Represents the business outcome of the operation
       * @domainConcept __UBIQUITOUS_LANGUAGE_TERM__
       */
      export type __ACTION_ENTITY_PASCAL_CASE__Output = {
        __USE_CASE_OUTPUT_FIELDS__
      }

      /**
       * __ACTION_ENTITY_PASCAL_CASE__UseCase interface
       * @description __USE_CASE_DESCRIPTION__
       * @pattern Command Pattern - Single Responsibility Principle
       * @layer Domain Layer - Framework agnostic business interface
       */
      export interface __ACTION_ENTITY_PASCAL_CASE__UseCase {
        /**
         * Execute the __ACTION_ENTITY_LOWER_CASE__ operation
         * @param input - The input parameters
         * @returns Promise with the operation output
         * @throws Domain errors when business rules are violated
         */
        execute: (input: __ACTION_ENTITY_PASCAL_CASE__Input) => Promise<__ACTION_ENTITY_PASCAL_CASE__Output>
      }
    validation_script: |
      echo "üîç Running lint check..."
      yarn lint
      if [ $? -ne 0 ]; then
        echo "‚ùå LINT FAILED - Attempting auto-fix..."
        yarn lint --fix
        if [ $? -ne 0 ]; then
          echo "‚ùå AUTO-FIX FAILED - Manual intervention required"
          exit 1
        fi
        echo "‚úÖ Lint errors auto-fixed, validating again..."
        yarn lint
        if [ $? -ne 0 ]; then
          echo "‚ùå LINT STILL FAILING - Manual fixes needed"
          exit 1
        fi
      fi
      echo "‚úÖ Lint passed"

      echo "üß™ Running tests with coverage..."
      yarn test --coverage
      if [ $? -ne 0 ]; then
        echo "‚ùå TESTS FAILED - Running specific test to identify issue..."
        yarn test --run --reporter=verbose
        echo "‚ùå Tests must be fixed manually"
        exit 1
      fi
      echo "‚úÖ Tests passed"

      echo "üì¶ Staging changes..."
      git add .

      echo "üíæ Creating commit..."
      git commit -m "feat(__FEATURE_NAME_KEBAB_CASE__): add __ACTION_ENTITY_KEBAB_CASE__ use case"
      if [ $? -ne 0 ]; then
        echo "‚ùå COMMIT FAILED - Checking git status..."
        git status
        exit 1
      fi
      echo "‚úÖ Successfully committed"

  # === DOMAIN LAYER: ERROR ===
  - id: 'create-error-__ERROR_NAME_KEBAB_CASE__'
    type: 'create_file'
    description: 'Create __ERROR_NAME_KEBAB_CASE__ domain error'
    status: 'PENDING' # PENDING | SUCCESS | FAILED | SKIPPED
    rlhf_score: null # -2, -1, 0, 1, 2
    execution_log: ''
    # AI-NOTE: For each step, you MUST populate this 'references' section.
    # Use 'context7' for external design patterns and 'serena' for internal codebase analysis.
    references:
      - type: 'external_pattern'
        source: 'context7'
        query: 'domain driven design error handling'
        url: 'https://github.com/...' # Link with your research phase
        description: 'Following DDD error handling patterns.'
      - type: 'internal_code_analysis'
        source: 'serena'
        tool: 'find_symbol'
        query: '*Error'
        description: 'Consistent with existing domain errors.'
    path: 'src/features/__FEATURE_NAME_KEBAB_CASE__/domain/errors/__ERROR_NAME_KEBAB_CASE__.ts'
    # AI-NOTE FOR +2 SCORE: Domain errors should represent business rule violations
    # Use ubiquitous language in error messages
    # Never expose technical details or implementation specifics
    template: |
      /**
       * Domain error thrown when __ERROR_DESCRIPTION__
       * Represents a business rule violation in the __FEATURE_NAME__ bounded context
       * @domainConcept __UBIQUITOUS_LANGUAGE_TERM__
       * @pattern Domain Error - Clean Architecture principle
       * @extends Error
       */
      export class __ERROR_NAME_PASCAL_CASE__Error extends Error {
        constructor() {
          super('__ERROR_MESSAGE__')
          this.name = '__ERROR_NAME_PASCAL_CASE__Error'
        }
      }
    validation_script: |
      echo "üîç Running lint check..."
      yarn lint
      if [ $? -ne 0 ]; then
        echo "‚ùå LINT FAILED - Attempting auto-fix..."
        yarn lint --fix
        if [ $? -ne 0 ]; then
          echo "‚ùå AUTO-FIX FAILED - Manual intervention required"
          exit 1
        fi
        echo "‚úÖ Lint errors auto-fixed"
      fi
      echo "‚úÖ Lint passed"

      echo "üß™ Running tests..."
      yarn test --coverage
      if [ $? -ne 0 ]; then
        echo "‚ùå TESTS FAILED"
        exit 1
      fi
      echo "‚úÖ Tests passed"

      echo "üì¶ Staging changes..."
      git add .

      echo "üíæ Creating commit..."
      git commit -m "feat(__FEATURE_NAME_KEBAB_CASE__): add __ERROR_NAME_KEBAB_CASE__ domain error"
      if [ $? -ne 0 ]; then
        echo "‚ùå COMMIT FAILED"
        exit 1
      fi
      echo "‚úÖ Successfully committed"

  # === DOMAIN LAYER: TEST HELPER ===
  - id: 'create-test-helper-__ACTION_ENTITY_KEBAB_CASE__'
    type: 'create_file'
    description: 'Create mock for __ACTION_ENTITY_PASCAL_CASE__ use case'
    status: 'PENDING' # PENDING | SUCCESS | FAILED | SKIPPED
    rlhf_score: null # -2, -1, 0, 1, 2
    execution_log: ''
    # AI-NOTE: For each step, you MUST populate this 'references' section.
    # Use 'context7' for external design patterns and 'serena' for internal codebase analysis.
    references:
      - type: 'external_pattern' # 'external_pattern' or 'internal_code_analysis'
        source: 'context7'
        query: 'test driven development mocks'
        url: 'https://github.com/...' # Link with your research phase
        description: 'Following TDD mock patterns.'
      - type: 'internal_code_analysis'
        source: 'serena'
        tool: 'find_symbol'
        query: 'mock*'
        description: 'Consistent with existing test helpers.'
    path: 'src/features/__FEATURE_NAME_KEBAB_CASE__/domain/test/mock-__ACTION_ENTITY_KEBAB_CASE__-use-case.ts'
    template: |
      import { vi } from 'vitest'
      import type { __ACTION_ENTITY_PASCAL_CASE__UseCase, __ACTION_ENTITY_PASCAL_CASE__Input, __ACTION_ENTITY_PASCAL_CASE__Output } from '../use-cases/__ACTION_ENTITY_KEBAB_CASE__'

      /**
       * Creates a mock instance of __ACTION_ENTITY_PASCAL_CASE__Input
       * @returns Mock input for testing
       */
      export const mock__ACTION_ENTITY_PASCAL_CASE__Input = (): __ACTION_ENTITY_PASCAL_CASE__Input => ({
        __MOCK_INPUT_DATA__
      })

      /**
       * Creates a mock instance of __ACTION_ENTITY_PASCAL_CASE__Output
       * @returns Mock output for testing
       */
      export const mock__ACTION_ENTITY_PASCAL_CASE__Output = (): __ACTION_ENTITY_PASCAL_CASE__Output => ({
        __MOCK_OUTPUT_DATA__
      })

      /**
       * Creates a mock instance of __ACTION_ENTITY_PASCAL_CASE__UseCase
       * @returns Mocked use case with vitest functions
       */
      export const mock__ACTION_ENTITY_PASCAL_CASE__UseCase = (): __ACTION_ENTITY_PASCAL_CASE__UseCase => ({
        execute: vi.fn()
      })
    validation_script: |
      echo "üîç Running lint check..."
      yarn lint
      if [ $? -ne 0 ]; then
        echo "‚ùå LINT FAILED"
        exit 1
      fi
      echo "‚úÖ Lint passed"

      echo "üß™ Running tests..."
      yarn test --coverage
      if [ $? -ne 0 ]; then
        echo "‚ùå TESTS FAILED"
        exit 1
      fi
      echo "‚úÖ Tests passed"

      echo "üì¶ Staging changes..."
      git add .

      echo "üíæ Creating commit..."
      git commit -m "test(__FEATURE_NAME_KEBAB_CASE__): add __ACTION_ENTITY_KEBAB_CASE__ use case test helpers"
      if [ $? -ne 0 ]; then
        echo "‚ùå COMMIT FAILED"
        exit 1
      fi
      echo "‚úÖ Successfully committed"

  # === REFACTORING STEP (OPTIONAL) ===
  # OPTIONAL STEP: You can add more steps here for additional use cases, errors, or test helpers as needed.
  - id: 'refactor-__FILE_TO_MODIFY_KEBAB_CASE__'
    type: 'refactor_file'
    description: 'Refactor __FILE_TO_MODIFY_PASCAL_CASE__ to incorporate new logic'
    status: 'PENDING' # PENDING | SUCCESS | FAILED | SKIPPED
    rlhf_score: null # -2, -1, 0, 1, 2
    execution_log: ''
    references:
      - type: 'internal_code_analysis'
        source: 'serena'
        tool: 'find_referencing_symbols'
        query: '__SYMBOL_BEING_CHANGED__'
        description: 'Refactoring affected files.'
    path: 'src/features/__FEATURE_NAME_KEBAB_CASE__/path/to/__FILE_TO_MODIFY_KEBAB_CASE__.ts'
    # CRITICAL FOR RLHF SCORE: The template MUST use REPLACE/WITH format for refactor_file steps
    # Missing these blocks will result in a CATASTROPHIC -2 score
    # Format requirements:
    # 1. MUST include <<<REPLACE>>> block with exact code to be replaced
    # 2. MUST include <<<WITH>>> block with new code
    # 3. MUST include closing tags: <<</REPLACE>>> and <<</WITH>>>
    # 4. The code in REPLACE block must match EXACTLY what's in the file
    template: |
      <<<REPLACE>>>
      // Old code to be replaced
      export type OldType = {
        fieldA: string;
      }
      <<</REPLACE>>>
      <<<WITH>>>
      // New code
      export type OldType = {
        fieldA: string;
        newFieldB: number;
      }
      <<</WITH>>>
    validation_script: |
      echo "üîç Running lint check..."
      yarn lint
      if [ $? -ne 0 ]; then
        echo "‚ùå LINT FAILED"
        exit 1
      fi
      echo "‚úÖ Lint passed"

      echo "üß™ Running tests..."
      yarn test --coverage
      if [ $? -ne 0 ]; then
        echo "‚ùå TESTS FAILED"
        exit 1
      fi
      echo "‚úÖ Tests passed"

      echo "üì¶ Staging changes..."
      git add .

      echo "üíæ Creating commit..."
      git commit -m "refactor(__FEATURE_NAME_KEBAB_CASE__): update __FILE_TO_MODIFY_KEBAB_CASE__"
      if [ $? -ne 0 ]; then
        echo "‚ùå COMMIT FAILED"
        exit 1
      fi
      echo "‚úÖ Successfully committed"

  # === DELETE STEP (ERROR RECOVERY) ===
  # AI-NOTE: This step is used by the AI during the self-correction loop.
  # When a 'create_file' step fails, the AI can generate an instance of this
  # step to delete the broken artifact before attempting a fix.
  - id: 'delete-file-__FILE_TO_DELETE_KEBAB_CASE__'
    type: 'delete_file'
    description: 'Delete file __FILE_TO_DELETE_PASCAL_CASE__ due to generation error'
    status: 'PENDING' # PENDING | SUCCESS | FAILED | SKIPPED
    rlhf_score: null # -2, -1, 0, 1, 2
    execution_log: ''
    references:
      - type: 'internal_correction'
        source: 'self'
        description: 'Deleting artifact from failed step.'
    path: 'src/features/__FEATURE_NAME_KEBAB_CASE__/path/to/__FILE_TO_DELETE_KEBAB_CASE__.ts'
    # AI-NOTE: The validation_script for a delete action should verify the file is gone
    # and then perform the standard quality checks before committing the deletion.
    validation_script: |
      echo "üóëÔ∏è Verifying file deletion..."
      if [ -f "src/features/__FEATURE_NAME_KEBAB_CASE__/path/to/__FILE_TO_DELETE_KEBAB_CASE__.ts" ]; then
        echo "‚ùå ERROR: File was not deleted."
        exit 1
      fi
      echo "‚úÖ File successfully deleted."

      echo "üîç Running lint check..."
      yarn lint
      if [ $? -ne 0 ]; then
        echo "‚ùå LINT FAILED"
        exit 1
      fi
      echo "‚úÖ Lint passed."

      echo "üì¶ Staging changes..."
      git add .

      echo "üíæ Creating commit..."
      git commit -m "chore(__FEATURE_NAME_KEBAB_CASE__): delete broken artifact"
      if [ $? -ne 0 ]; then
        echo "‚ùå COMMIT FAILED"
        exit 1
      fi
      echo "‚úÖ Successfully committed."

  # === FINAL: CREATE PULL REQUEST ===
  - id: 'create-pull-request'
    type: 'pull_request'
    description: 'Create pull request for __FEATURE_NAME_PASCAL_CASE__ implementation'
    status: 'PENDING' # PENDING | SUCCESS | FAILED | SKIPPED
    rlhf_score: null # -2, -1, 0, 1, 2
    execution_log: ''
    references:
      - type: 'internal_guideline'
        source: 'GIT_WORKFLOW.md'
        description: 'Following PR process for feature integration.'
    action:
      target_branch: 'main'
      source_branch: 'feat/__FEATURE_NAME_KEBAB_CASE__'
      title: 'feat(__FEATURE_NAME_KEBAB_CASE__): implement clean architecture layers'
    validation_script: |
      echo "üöÄ Preparing to create pull request..."

      # Push the current branch to remote
      echo "üì§ Pushing branch to remote..."
      git push --set-upstream origin feat/__FEATURE_NAME_KEBAB_CASE__
      if [ $? -ne 0 ]; then
        echo "‚ùå ERROR: Failed to push branch to remote"
        exit 1
      fi

      # Check if gh CLI is available
      if ! command -v gh &> /dev/null; then
        echo "‚ö†Ô∏è GitHub CLI (gh) is not installed."
        echo "üìã Please create PR manually"
        exit 0
      fi

      # Create the pull request
      echo "üîÑ Creating pull request..."
      PR_BODY="## Summary

      Implementation of Clean Architecture layers for __FEATURE_NAME_PASCAL_CASE__ feature.

      ### Changes included:
      - Domain layer with use case interfaces
      - Domain errors
      - Test helpers and mocks

      ### Architecture Compliance:
      - ‚úÖ Clean Architecture principles
      - ‚úÖ No dependency violations
      - ‚úÖ All tests passing
      - ‚úÖ Lint checks passed
      - ‚úÖ RLHF score: +2 (PERFECT)

      ### Generated by:
      - Template: TEMPLATE.yaml
      - Date: $(date +%Y-%m-%d)

      ---
      ü§ñ Generated with spec-kit-clean-architecture"

      gh pr create \
        --base main \
        --head feat/__FEATURE_NAME_KEBAB_CASE__ \
        --title "feat(__FEATURE_NAME_KEBAB_CASE__): implement clean architecture layers" \
        --body "$PR_BODY" \
        --assignee @me

      if [ $? -eq 0 ]; then
        echo "‚úÖ Pull request created successfully!"
        PR_URL=$(gh pr view --json url -q .url)
        echo "üìé Pull Request URL: $PR_URL"
        gh pr view --web
      else
        echo "‚ö†Ô∏è Could not create PR automatically. Please create manually."
      fi

# ------------------------------------------------------------------------------
# AI-NOTE: IMMUTABLE DOCUMENTATION SECTIONS AHEAD.
# Copy these sections verbatim. The [placeholders] inside the commands
# are for HUMAN examples and MUST NOT be replaced by the AI.
# ------------------------------------------------------------------------------

# ------------------------------------------------------------------------------
# TROUBLESHOOTING & RECOVERY
# ------------------------------------------------------------------------------

troubleshooting:
  lint_fails:
    - 'DO NOT commit - Fix all lint errors first'
    - 'Check for unused imports'
    - 'Verify proper TypeScript types'
    - 'Ensure no console.log statements'
    - 'Run yarn lint --fix to auto-fix when possible'

  tests_fail:
    - 'DO NOT commit - All tests must pass'
    - 'Check if mocks match the actual interfaces'
    - 'Verify Input/Output types are correct'
    - 'Ensure test coverage meets requirements'
    - 'Run specific test: yarn test [test-file-path]'

  typescript_fails:
    - 'Check all type definitions match'
    - 'Ensure no missing imports'
    - 'Verify interface implementations are complete'
    - 'Run yarn tsc --noEmit to check types'

# Refactoring checklist
refactoring:
  before_refactoring: |
    # Check current status and differences
    echo "üìä Checking current changes..."
    git status
    git diff

    # Ensure clean working directory
    echo "‚úÖ Saving current work..."
    git stash save "WIP: before refactoring"

    # Create refactoring branch
    echo "üåø Creating refactor branch..."
    git checkout -b refactor/[feature-name]

    # Run tests to ensure starting point is stable
    echo "üß™ Validating current state..."
    yarn test --run
    if [ $? -ne 0 ]; then
      echo "‚ùå Tests failing before refactor - fix first!"
      exit 1
    fi
    echo "‚úÖ Ready to refactor"

  during_refactoring: |
    # After each change, check what was modified
    echo "üîç Reviewing changes..."
    git diff --stat
    git diff

    # Validate the change
    yarn lint && yarn test --run

    # Commit atomically
    git add -p  # Interactive staging
    git commit -m "refactor([feature-name]): [specific change description]"

    # Show what was changed
    git show --stat

  common_scenarios:
    - name: 'Splitting a use case'
      wrong_example: |
        interface CreateUserAndSendEmailUseCase {
          execute: (input: CreateUserAndSendEmailInput) => Promise<CreateUserAndSendEmailOutput>
        }
      correct_example: |
        interface CreateUserUseCase {
          execute: (input: CreateUserInput) => Promise<CreateUserOutput>
        }
        interface SendWelcomeEmailUseCase {
          execute: (input: SendWelcomeEmailInput) => Promise<SendWelcomeEmailOutput>
        }

    - name: 'Renaming for clarity'
      script: |
        # Find all occurrences
        grep -r "[OldName]" src/features/[feature-name]/
        # Perform rename
        # Validate
        yarn lint && yarn test --run
        # Commit
        git add .
        git commit -m "refactor: rename [OldName] to [NewName]"

# Recovery steps
recovery:
  accidental_commit: |
    # Revert the last commit but keep changes
    git reset --soft HEAD~1
    # Fix the issues
    # Re-run validation
    yarn lint
    yarn test --coverage
    # Commit again with fixed code
    git add .
    git commit -m "[original message] - fixed"

  domain_polluted: |
    # Check for violations
    echo "üîç Checking for domain violations..."
    grep -r "class.*{.*calculate\|validate\|process" src/features/[feature-name]/domain/
    grep -r "import.*axios\|fetch\|http" src/features/[feature-name]/domain/
    grep -r "console\." src/features/[feature-name]/domain/
    # Fix and validate
    yarn lint
    yarn test --run
    # Commit cleanup
    git add .
    git commit -m "refactor: remove business logic from domain layer"

# AI Guidelines from templates/DOMAIN_TEMPLATES.md
ai_guidelines:
  - 'Always validate before committing: Run lint first, Run tests second, Only commit if both pass'
  - 'If generation fails: Identify the specific error, Fix only that error, Re-run validation, Do NOT proceed until fixed'
  - 'Follow the principle: One use case = One file = One responsibility'
  - 'If tempted to add "And" in a use case name, split it'
  - 'When in doubt: Choose simplicity over complexity, Split rather than combine, Ask for clarification rather than assume'
  - 'MUST generate different case styles from the input names (e.g., "Add Item To Cart" becomes: PascalCase=AddItemToCart, kebab-case=add-item-to-cart, lower case=add item to cart).'
  - 'MUST replace ALL placeholder variables (like __FEATURE_NAME_KEBAB_CASE__) with actual values'
  - 'MUST NOT leave any placeholder variables in the final implementation'
  - 'MUST NOT replace any [placeholders] found inside documentation sections like refactoring or recovery'
  - 'MUST use vitest, NOT jest'
  - 'MUST follow all domain rules - no business logic, no external dependencies'
  - 'MUST follow all Clean Architecture rules'
  - 'MUST use REPLACE/WITH format for refactor_file steps'

# ------------------------------------------------------------------------------
# AI-NOTE: TASK EVALUATION SECTION.
# After the entire execution is complete, this section will be populated by a
# human reviewer or an evaluation script.
# ------------------------------------------------------------------------------

# ------------------------------------------------------------------------------
# EVALUATION SECTION
# ------------------------------------------------------------------------------

evaluation:
  # AI-NOTE: This final_status will be 'SUCCESS' if all steps passed, or 'FAILED' if any step failed.
  final_status: 'PENDING' # PENDING | SUCCESS | FAILED
  # AI-NOTE: The final_rlhf_score is calculated automatically based on execution quality
  # -2: Catastrophic errors (architecture violations, wrong REPLACE/WITH format)
  # -1: Runtime errors (lint, tests, git failures)
  #  0: Low confidence (system uncertain, prevents hallucinations)
  # +1: Good execution but missing architectural elements
  # +2: Perfect with Clean Architecture, DDD, ubiquitous language
  final_rlhf_score: null # -2, -1, 0, 1, 2
  # AI-NOTE: The system automatically analyzes patterns and learns from each execution
  # This text is enhanced by automated RLHF analysis for continuous improvement
  reviewer_summary: |
    - What went well:
      - ...
    - Areas for improvement:
      - ...
  # AI-NOTE: This section lists actionable suggestions for improving the master templates or prompts.
  # This is the key to the continuous learning loop.
  template_improvement_suggestions:
    - target_template: 'TEMPLATE.yaml'
      target_step_id: 'create-use-case-__ACTION_ENTITY_KEBAB_CASE__'
      suggestion: 'The generated mock data was too simplistic. The template should be updated to include more realistic data generation.'
      priority: 'medium'